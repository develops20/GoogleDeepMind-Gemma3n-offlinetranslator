{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":397953,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":326098,"modelId":317146}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install tflite-runtime","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-28T02:12:02.771202Z","iopub.execute_input":"2025-06-28T02:12:02.771504Z","iopub.status.idle":"2025-06-28T02:12:07.116840Z","shell.execute_reply.started":"2025-06-28T02:12:02.771480Z","shell.execute_reply":"2025-06-28T02:12:07.115963Z"}},"outputs":[{"name":"stdout","text":"Collecting tflite-runtime\n  Downloading tflite_runtime-2.14.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.4 kB)\nRequirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from tflite-runtime) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->tflite-runtime) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->tflite-runtime) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->tflite-runtime) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->tflite-runtime) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->tflite-runtime) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->tflite-runtime) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->tflite-runtime) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->tflite-runtime) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.2->tflite-runtime) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.2->tflite-runtime) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.2->tflite-runtime) (2024.2.0)\nDownloading tflite_runtime-2.14.0-cp311-cp311-manylinux2014_x86_64.whl (2.4 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: tflite-runtime\nSuccessfully installed tflite-runtime-2.14.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"#!/usr/bin/env python3\n\"\"\"\nGemma 3N Translation Notebook - Embedding-Based Fallback with GPU Support\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport sentencepiece as spm\nimport zipfile\nimport time\nfrom typing import Dict, List\n\n# Ensure GPU is used if available\nphysical_devices = tf.config.list_physical_devices('GPU')\nif physical_devices:\n    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n    print(\"‚úÖ TensorFlow GPU enabled\")\nelse:\n    print(\"‚ö†Ô∏è GPU not detected, using CPU\")\n\n# Path to the Gemma 3N model file\nMODEL_PATH = \"/kaggle/input/gemma-3n/tflite/gemma-3n-e2b-it-int4/1/gemma-3n-E2B-it-int4.task\"\nEXTRACT_DIR = \"/tmp/gemma3n_extracted\"\n\n# Verify model file exists\nif os.path.exists(MODEL_PATH):\n    print(f\"‚úÖ Model found at: {MODEL_PATH}\")\n    print(f\"üìä Model size: {os.path.getsize(MODEL_PATH) / (1024*1024):.1f} MB\")\nelse:\n    print(\"‚ùå Model file not found. Please ensure the dataset is properly added.\")\n    exit(1)\n\nclass Gemma3nTranslator:\n    def __init__(self, model_path: str):\n        \"\"\"Initialize the Gemma 3N translator with TFLite and SentencePiece\"\"\"\n        self.model_path = model_path\n        self.tokenizer = None\n        self.embedder = None\n        self.phrasebook = {}\n        self.gpu_enabled = False\n        self._setup()\n\n    def _setup(self):\n        \"\"\"Setup tokenizer and embedder with GPU delegate if available\"\"\"\n        try:\n            # Extract model components\n            os.makedirs(EXTRACT_DIR, exist_ok=True)\n            with zipfile.ZipFile(self.model_path, 'r') as zf:\n                zf.extractall(EXTRACT_DIR)\n\n            # Load tokenizer\n            tokenizer_path = os.path.join(EXTRACT_DIR, 'TOKENIZER_MODEL')\n            if os.path.exists(tokenizer_path):\n                self.tokenizer = spm.SentencePieceProcessor()\n                self.tokenizer.Load(tokenizer_path)\n                print(f\"‚úÖ Tokenizer loaded: {self.tokenizer.GetPieceSize()} tokens\")\n            else:\n                raise FileNotFoundError(\"Tokenizer model not found\")\n\n            # Load embedder with GPU delegate\n            embedder_path = os.path.join(EXTRACT_DIR, 'TF_LITE_EMBEDDER')\n            if os.path.exists(embedder_path):\n                try:\n                    # Attempt to load GPU delegate\n                    # Note: Kaggle may not have libtflite_gpu_delegate.so; try CPU fallback\n                    delegate = None\n                    if os.path.exists('/usr/lib/libtflite_gpu_delegate.so'):\n                        delegate = tf.lite.experimental.delegates.Delegate(\n                            library='libtflite_gpu_delegate.so'\n                        )\n                    self.embedder = tf.lite.Interpreter(\n                        model_path=embedder_path,\n                        experimental_delegates=[delegate] if delegate else []\n                    )\n                    self.gpu_enabled = bool(delegate)\n                    print(\"‚úÖ TFLite GPU delegate enabled\" if self.gpu_enabled else \"‚ö†Ô∏è GPU delegate not available, using CPU\")\n                except Exception as e:\n                    print(f\"‚ö†Ô∏è GPU delegate failed: {str(e)}. Falling back to CPU.\")\n                    self.embedder = tf.lite.Interpreter(model_path=embedder_path, num_threads=4)\n                    self.gpu_enabled = False\n                self.embedder.allocate_tensors()\n                print(\"‚úÖ Embedder loaded\")\n            else:\n                raise FileNotFoundError(\"Embedder model not found\")\n\n        except Exception as e:\n            print(f\"‚ùå Setup error: {str(e)}. Translation will not work until resolved.\")\n            self.embedder = None\n\n    def _get_embedding(self, text: str) -> np.ndarray:\n        \"\"\"Get average embedding for text\"\"\"\n        if not self.embedder or not self.tokenizer:\n            return np.zeros(2048)\n\n        tokens = self.tokenizer.EncodeAsIds(text)[:50]\n        if not tokens:\n            return np.zeros(2048)\n\n        input_details = self.embedder.get_input_details()\n        output_details = self.embedder.get_output_details()\n        embeddings = []\n\n        for token_id in tokens:\n            input_data = np.array([[token_id]], dtype=np.int32)\n            self.embedder.set_tensor(input_details[0]['index'], input_data)\n            self.embedder.invoke()\n            embedding = self.embedder.get_tensor(output_details[0]['index'])\n            embeddings.append(embedding[0, 0, :])\n\n        return np.mean(embeddings, axis=0)\n\n    def translate(self, text: str, target_language: str = \"Arabic\", source_language: str = \"English\") -> str:\n        \"\"\"Translate text using embedding-based similarity\"\"\"\n        if not self.embedder or not self.tokenizer:\n            return \"‚ùå Model not initialized\"\n        if target_language not in self.phrasebook:\n            return f\"‚ùå No phrasebook for {target_language}\"\n\n        start_time = time.time()\n        input_emb = self._get_embedding(text)\n        if np.all(input_emb == 0):\n            return \"‚ùå Invalid input text\"\n\n        best_match = None\n        best_sim = -1\n\n        for eng, trans in self.phrasebook[target_language].items():\n            eng_emb = self._get_embedding(eng)\n            if np.all(eng_emb == 0):\n                continue\n            sim = np.dot(input_emb, eng_emb) / (max(np.linalg.norm(input_emb) * np.linalg.norm(eng_emb), 1e-10))\n            if sim > best_sim:\n                best_sim = sim\n                best_match = trans\n\n        end_time = time.time()\n        print(f\"‚è±Ô∏è Translation completed in {end_time - start_time:.2f} seconds (GPU: {self.gpu_enabled})\")\n        if best_sim < 0.8:\n            return \"‚ùå No reliable translation found\"\n        return best_match or \"‚ùå No matching translation found\"\n\n    def batch_translate(self, texts: List[str], target_language: str = \"Arabic\") -> List[str]:\n        \"\"\"Translate multiple texts\"\"\"\n        translations = []\n        for i, text in enumerate(texts):\n            print(f\"Translating {i+1}/{len(texts)}: {text[:50]}...\")\n            translation = self.translate(text, target_language)\n            translations.append(translation)\n        return translations\n\n# Initialize translator\ntranslator = Gemma3nTranslator(MODEL_PATH)\n\n# Supported languages\nSUPPORTED_LANGUAGES = {\n    \"Arabic\": \"ÿßŸÑÿπÿ±ÿ®Ÿäÿ©\",\n    \"Chinese\": \"‰∏≠Êñá\",\n    \"Spanish\": \"Espa√±ol\",\n    \"French\": \"Fran√ßais\",\n    \"German\": \"Deutsch\",\n    \"Italian\": \"Italiano\",\n    \"Portuguese\": \"Portugu√™s\",\n    \"Russian\": \"–†—É—Å—Å–∫–∏–π\",\n    \"Japanese\": \"Êó•Êú¨Ë™û\",\n    \"Korean\": \"ÌïúÍµ≠Ïñ¥\",\n    \"Hindi\": \"‡§π‡§ø‡§®‡•ç‡§¶‡•Ä\",\n    \"Turkish\": \"T√ºrk√ße\",\n    \"Dutch\": \"Nederlands\",\n    \"Swedish\": \"Svenska\",\n    \"Norwegian\": \"Norsk\",\n    \"Polish\": \"Polski\",\n    \"Czech\": \"ƒåe≈°tina\",\n    \"Greek\": \"ŒïŒªŒªŒ∑ŒΩŒπŒ∫Œ¨\",\n    \"Hebrew\": \"◊¢◊ë◊®◊ô◊™\",\n    \"Thai\": \"‡πÑ‡∏ó‡∏¢\"\n}\n\nprint(\"üåç Supported Languages:\")\nfor lang, native in SUPPORTED_LANGUAGES.items():\n    print(f\"‚Ä¢ {lang} ({native})\")\n\n# Expanded phrasebook\ntranslator.phrasebook = {\n    \"Arabic\": {\n        \"Hello\": \"ŸÖÿ±ÿ≠ÿ®ÿß\",\n        \"Good morning\": \"ÿµÿ®ÿßÿ≠ ÿßŸÑÿÆŸäÿ±\",\n        \"Good evening\": \"ŸÖÿ≥ÿßÿ° ÿßŸÑÿÆŸäÿ±\",\n        \"Where is the bathroom?\": \"ÿ£ŸäŸÜ ÿßŸÑÿ≠ŸÖÿßŸÖÿü\",\n        \"I need help\": \"ÿ£ÿ≠ÿ™ÿßÿ¨ ÿ•ŸÑŸâ ŸÖÿ≥ÿßÿπÿØÿ©\",\n        \"How much does this scooter cost for 1 day?\": \"ŸÉŸÖ ÿ™ŸÉŸÑŸÅÿ© Ÿáÿ∞ÿß ÿßŸÑÿØÿ±ÿßÿ¨ÿ© ÿßŸÑŸÜÿßÿ±Ÿäÿ© ŸÑŸÖÿØÿ© ŸäŸàŸÖ Ÿàÿßÿ≠ÿØÿü\",\n        \"Where is the bus station?\": \"ÿ£ŸäŸÜ ŸÖÿ≠ÿ∑ÿ© ÿßŸÑÿ≠ÿßŸÅŸÑÿßÿ™ÿü\",\n        \"I would like to order\": \"ÿ£ŸàÿØ ÿ£ŸÜ ÿ£ÿ∑ŸÑÿ®\",\n        \"Can I see the menu?\": \"ŸáŸÑ ŸäŸÖŸÉŸÜŸÜŸä ÿ±ÿ§Ÿäÿ© ÿßŸÑŸÇÿßÿ¶ŸÖÿ©ÿü\",\n        \"I need a doctor\": \"ÿ£ÿ≠ÿ™ÿßÿ¨ ÿ•ŸÑŸâ ÿ∑ÿ®Ÿäÿ®\",\n        \"Call the police\": \"ÿßÿ™ÿµŸÑ ÿ®ÿßŸÑÿ¥ÿ±ÿ∑ÿ©\",\n        \"Where is the nearest restaurant?\": \"ÿ£ŸäŸÜ ÿ£ŸÇÿ±ÿ® ŸÖÿ∑ÿπŸÖÿü\",\n        \"Can you help me find a hotel?\": \"ŸáŸÑ ŸäŸÖŸÉŸÜŸÉ ŸÖÿ≥ÿßÿπÿØÿ™Ÿä ŸÅŸä ÿßŸÑÿπÿ´Ÿàÿ± ÿπŸÑŸâ ŸÅŸÜÿØŸÇÿü\",\n        \"What time does the store close?\": \"ŸÅŸä ÿ£Ÿä ŸàŸÇÿ™ Ÿäÿ∫ŸÑŸÇ ÿßŸÑŸÖÿ™ÿ¨ÿ±ÿü\",\n        \"I would like to order coffee, please.\": \"ÿ£ŸàÿØ ÿ∑ŸÑÿ® ŸÇŸáŸàÿ©ÿå ŸÖŸÜ ŸÅÿ∂ŸÑŸÉ.\",\n        \"How do I get to the airport?\": \"ŸÉŸäŸÅ ÿ£ÿµŸÑ ÿ•ŸÑŸâ ÿßŸÑŸÖÿ∑ÿßÿ±ÿü\",\n        \"Is there a pharmacy nearby?\": \"ŸáŸÑ ŸäŸàÿ¨ÿØ ÿµŸäÿØŸÑŸäÿ© ŸÇÿ±Ÿäÿ®ÿ©ÿü\",\n        \"What is the weather like today?\": \"ŸÉŸäŸÅ ŸáŸà ÿßŸÑÿ∑ŸÇÿ≥ ÿßŸÑŸäŸàŸÖÿü\",\n        \"Where can I find good local food?\": \"ÿ£ŸäŸÜ ŸäŸÖŸÉŸÜŸÜŸä ÿßŸÑÿπÿ´Ÿàÿ± ÿπŸÑŸâ ÿ∑ÿπÿßŸÖ ŸÖÿ≠ŸÑŸä ÿ¨ŸäÿØÿü\",\n        \"Is there wifi in the hotel?\": \"ŸáŸÑ ŸäŸàÿ¨ÿØ ŸàÿßŸä ŸÅÿßŸä ŸÅŸä ÿßŸÑŸÅŸÜÿØŸÇÿü\",\n        \"How do I get to the train station?\": \"ŸÉŸäŸÅ ÿ£ÿµŸÑ ÿ•ŸÑŸâ ŸÖÿ≠ÿ∑ÿ© ÿßŸÑŸÇÿ∑ÿßÿ±ÿü\",\n        \"Can you recommend a good restaurant nearby?\": \"ŸáŸÑ ŸäŸÖŸÉŸÜŸÉ ÿßŸÑÿ™ŸàÿµŸäÿ© ÿ®ŸÖÿ∑ÿπŸÖ ÿ¨ŸäÿØ ŸÇÿ±Ÿäÿ®ÿü\",\n        \"What time is the meeting?\": \"ŸÖÿß ŸáŸà ŸÖŸàÿπÿØ ÿßŸÑÿßÿ¨ÿ™ŸÖÿßÿπÿü\",\n        \"Can you send me the report?\": \"ŸáŸÑ ŸäŸÖŸÉŸÜŸÉ ÿ•ÿ±ÿ≥ÿßŸÑ ÿßŸÑÿ™ŸÇÿ±Ÿäÿ± ŸÑŸäÿü\",\n        \"Let's schedule a call for tomorrow\": \"ÿØÿπŸÜÿß ŸÜÿ≠ÿØÿØ ŸÖŸàÿπÿØ ŸÖŸÉÿßŸÑŸÖÿ© ÿ∫ÿØŸãÿß\",\n        \"The project deadline is next week\": \"ÿßŸÑŸÖŸàÿπÿØ ÿßŸÑŸÜŸáÿßÿ¶Ÿä ŸÑŸÑŸÖÿ¥ÿ±Ÿàÿπ ÿßŸÑÿ£ÿ≥ÿ®Ÿàÿπ ÿßŸÑŸÖŸÇÿ®ŸÑ\",\n        \"Thank you for your presentation\": \"ÿ¥ŸÉÿ±ÿß ŸÑÿπÿ±ÿ∂ŸÉ ÿßŸÑÿ™ŸÇÿØŸäŸÖŸä\"\n    },\n    \"Chinese\": {\n        \"Hello\": \"‰Ω†Â•Ω\",\n        \"Good morning\": \"Êó©‰∏äÂ•Ω\",\n        \"Good evening\": \"Êôö‰∏äÂ•Ω\",\n        \"Where is the bathroom?\": \"Ê¥óÊâãÈó¥Âú®Âì™ÈáåÔºü\",\n        \"I need help\": \"ÊàëÈúÄË¶ÅÂ∏ÆÂä©\",\n        \"How much does this scooter cost for 1 day?\": \"ËøôËæÜË∏èÊùøËΩ¶‰∏ÄÂ§©Â§öÂ∞ëÈí±Ôºü\",\n        \"Where is the bus station?\": \"ÂÖ¨‰∫§ËΩ¶Á´ôÂú®Âì™ÈáåÔºü\",\n        \"I would like to order\": \"ÊàëÊÉ≥ÁÇπËèú\",\n        \"Can I see the menu?\": \"ÊàëÂèØ‰ª•ÁúãËèúÂçïÂêóÔºü\",\n        \"I need a doctor\": \"ÊàëÈúÄË¶ÅÂåªÁîü\",\n        \"Call the police\": \"Êä•Ë≠¶\",\n        \"Where is the nearest restaurant?\": \"ÊúÄËøëÁöÑÈ§êÂéÖÂú®Âì™ÈáåÔºü\",\n        \"Can you help me find a hotel?\": \"‰Ω†ËÉΩÂ∏ÆÊàëÊâæ‰∏ÄÂÆ∂ÈÖíÂ∫óÂêóÔºü\",\n        \"What time does the store close?\": \"ÂïÜÂ∫ó‰ªÄ‰πàÊó∂ÂÄôÂÖ≥Èó®Ôºü\",\n        \"I would like to order coffee, please.\": \"ÊàëÊÉ≥ÁÇπÊùØÂíñÂï°ÔºåË∞¢Ë∞¢„ÄÇ\",\n        \"How do I get to the airport?\": \"ÊÄé‰πàÂéªÊú∫Âú∫Ôºü\",\n        \"Is there a pharmacy nearby?\": \"ÈôÑËøëÊúâËçØÂ∫óÂêóÔºü\",\n        \"What is the weather like today?\": \"‰ªäÂ§©Â§©Ê∞îÊÄé‰πàÊ†∑Ôºü\",\n        \"Where can I find good local food?\": \"Âì™ÈáåÂèØ‰ª•ÊâæÂà∞Â•ΩÁöÑÂΩìÂú∞ÁæéÈ£üÔºü\",\n        \"Is there wifi in the hotel?\": \"ÈÖíÂ∫óÊúâÊó†Á∫øÁΩëÁªúÂêóÔºü\",\n        \"How do I get to the train station?\": \"ÊÄé‰πàÂéªÁÅ´ËΩ¶Á´ôÔºü\",\n        \"Can you recommend a good restaurant nearby?\": \"‰Ω†ËÉΩÊé®Ëçê‰∏ÄÂÆ∂ÈôÑËøëÁöÑÈ§êÂéÖÂêóÔºü\",\n        \"What time is the meeting?\": \"‰ºöËÆÆÊòØ‰ªÄ‰πàÊó∂Èó¥Ôºü\",\n        \"Can you send me the report?\": \"‰Ω†ËÉΩÊääÊä•ÂëäÂèëÁªôÊàëÂêóÔºü\",\n        \"Let's schedule a call for tomorrow\": \"Êàë‰ª¨ÂÆâÊéíÊòéÂ§©ÈÄöËØùÂêß\",\n        \"The project deadline is next week\": \"È°πÁõÆÊà™Ê≠¢Êó•ÊúüÊòØ‰∏ãÂë®\",\n        \"Thank you for your presentation\": \"ÊÑüË∞¢‰Ω†ÁöÑÊºîËÆ≤\"\n    },\n    \"Spanish\": {\n        \"Hello\": \"Hola\",\n        \"Good morning\": \"Buenos d√≠as\",\n        \"Good evening\": \"Buenas noches\",\n        \"Where is the bathroom?\": \"¬øD√≥nde est√° el ba√±o?\",\n        \"I need help\": \"Necesito ayuda\",\n        \"How much does this scooter cost for 1 day?\": \"¬øCu√°nto cuesta este scooter por un d√≠a?\",\n        \"Where is the bus station?\": \"¬øD√≥nde est√° la estaci√≥n de autobuses?\",\n        \"I would like to order\": \"Quiero pedir\",\n        \"Can I see the menu?\": \"¬øPuedo ver el men√∫?\",\n        \"I need a doctor\": \"Necesito un m√©dico\",\n        \"Call the police\": \"Llama a la polic√≠a\",\n        \"Where is the nearest restaurant?\": \"¬øD√≥nde est√° el restaurante m√°s cercano?\",\n        \"Can you help me find a hotel?\": \"¬øPuedes ayudarme a encontrar un hotel?\",\n        \"What time does the store close?\": \"¬øA qu√© hora cierra la tienda?\",\n        \"I would like to order coffee, please.\": \"Quiero pedir un caf√©, por favor.\",\n        \"How do I get to the airport?\": \"¬øC√≥mo llego al aeropuerto?\",\n        \"Is there a pharmacy nearby?\": \"¬øHay una farmacia cerca?\",\n        \"What is the weather like today?\": \"¬øC√≥mo est√° el clima hoy?\",\n        \"Where can I find good local food?\": \"¬øD√≥nde puedo encontrar comida local buena?\",\n        \"Is there wifi in the hotel?\": \"¬øHay wifi en el hotel?\",\n        \"How do I get to the train station?\": \"¬øC√≥mo llego a la estaci√≥n de tren?\",\n        \"Can you recommend a good restaurant nearby?\": \"¬øPuedes recomendar un buen restaurante cerca?\",\n        \"What time is the meeting?\": \"¬øA qu√© hora es la reuni√≥n?\",\n        \"Can you send me the report?\": \"¬øPuedes enviarme el informe?\",\n        \"Let's schedule a call for tomorrow\": \"Programemos una llamada para ma√±ana\",\n        \"The project deadline is next week\": \"La fecha l√≠mite del proyecto es la pr√≥xima semana\",\n        \"Thank you for your presentation\": \"Gracias por tu presentaci√≥n\"\n    },\n    \"French\": {\n        \"Hello\": \"Bonjour\",\n        \"Good morning\": \"Bonjour\",\n        \"Good evening\": \"Bonsoir\",\n        \"Where is the bathroom?\": \"O√π sont les toilettes ?\",\n        \"I need help\": \"J'ai besoin d'aide\",\n        \"How much does this scooter cost for 1 day?\": \"Combien co√ªte ce scooter pour une journ√©e ?\",\n        \"Where is the bus station?\": \"O√π est la gare routi√®re ?\",\n        \"I would like to order\": \"Je voudrais commander\",\n        \"Can I see the menu?\": \"Puis-je voir le menu ?\",\n        \"I need a doctor\": \"J'ai besoin d'un m√©decin\",\n        \"Call the police\": \"Appelez la police\",\n        \"Where is the nearest restaurant?\": \"O√π se trouve le restaurant le plus proche ?\",\n        \"Can you help me find a hotel?\": \"Pouvez-vous m'aider √† trouver un h√¥tel ?\",\n        \"What time does the store close?\": \"√Ä quelle heure le magasin ferme-t-il ?\",\n        \"I would like to order coffee, please.\": \"Je voudrais commander un caf√©, s'il vous pla√Æt.\",\n        \"How do I get to the airport?\": \"Comment puis-je me rendre √† l'a√©roport ?\",\n        \"Is there a pharmacy nearby?\": \"Y a-t-il une pharmacie √† proximit√© ?\",\n        \"What is the weather like today?\": \"Quel temps fait-il aujourd'hui ?\",\n        \"Where can I find good local food?\": \"O√π puis-je trouver de la bonne nourriture locale ?\",\n        \"Is there wifi in the hotel?\": \"Y a-t-il du wifi dans l'h√¥tel ?\",\n        \"How do I get to the train station?\": \"Comment puis-je me rendre √† la gare ?\",\n        \"Can you recommend a good restaurant nearby?\": \"Pouvez-vous recommander un bon restaurant √† proximit√© ?\",\n        \"What time is the meeting?\": \"√Ä quelle heure est la r√©union ?\",\n        \"Can you send me the report?\": \"Pouvez-vous m'envoyer le rapport ?\",\n        \"Let's schedule a call for tomorrow\": \"Programmons un appel pour demain\",\n        \"The project deadline is next week\": \"La date limite du projet est la semaine prochaine\",\n        \"Thank you for your presentation\": \"Merci pour votre pr√©sentation\"\n    }\n}\n\nprint(\"üîÑ Starting Translation Examples...\")\nprint(\"=\" * 60)\n\n# Translate to Arabic\nprint(\"\\nüá∏üá¶ ENGLISH ‚Üí ARABIC\")\nprint(\"-\" * 30)\nfor sentence in [\"How much does this scooter cost for 1 day?\", \"Where is the nearest restaurant?\",\n                 \"Can you help me find a hotel?\", \"What time does the store close?\"]:\n    translation = translator.translate(sentence, \"Arabic\")\n    print(f\"üá∫üá∏ EN: {sentence}\")\n    print(f\"üá∏üá¶ AR: {translation}\")\n    print()\n\n# Translate to Chinese\nprint(\"\\nüá®üá≥ ENGLISH ‚Üí CHINESE\")\nprint(\"-\" * 30)\nfor sentence in [\"I would like to order coffee, please.\", \"How do I get to the airport?\",\n                 \"Is there a pharmacy nearby?\", \"What is the weather like today?\"]:\n    translation = translator.translate(sentence, \"Chinese\")\n    print(f\"üá∫üá∏ EN: {sentence}\")\n    print(f\"üá®üá≥ ZH: {translation}\")\n    print()\n\n# Interactive translator\ndef interactive_translator():\n    print(\"üåç Gemma 3N Interactive Translator\")\n    print(\"=\" * 40)\n    print(\"Available languages:\", \", \".join(SUPPORTED_LANGUAGES.keys()))\n    print(\"Type 'quit' to exit\\n\")\n\n    while True:\n        text = input(\"üìù Enter text to translate (English): \")\n        if text.lower() == 'quit':\n            break\n        target_lang = input(\"üéØ Target language: \")\n        if target_lang not in SUPPORTED_LANGUAGES:\n            print(f\"‚ùå Language '{target_lang}' not supported. Using Arabic.\")\n            target_lang = \"Arabic\"\n        translation = translator.translate(text, target_lang)\n        print(f\"‚úÖ Translation: {translation}\")\n        print(\"-\" * 50)\n\n# Uncomment to run interactive mode\n# interactive_translator()\n\n# Performance analysis\ndef analyze_performance():\n    test_text = \"How much does this scooter cost for 1 day?\"\n    results = []\n\n    print(\"üìä Performance Analysis\")\n    print(\"=\" * 40)\n\n    for language in [\"Arabic\", \"Chinese\", \"Spanish\", \"French\"]:\n        start_time = time.time()\n        translation = translator.translate(test_text, language)\n        end_time = time.time()\n\n        results.append({\n            'Language': language,\n            'Translation': translation,\n            'Time (seconds)': round(end_time - start_time, 2),\n            'Characters': len(translation)\n        })\n\n    df = pd.DataFrame(results)\n    print(df.to_string(index=False))\n\n    print(f\"\\nüìä Average translation time: {df['Time (seconds)'].mean():.2f} seconds\")\n    print(f\"üìä Fastest translation: {df.loc[df['Time (seconds)'].idxmin(), 'Language']} ({df['Time (seconds)'].min():.2f}s)\")\n    print(f\"üìä Slowest translation: {df.loc[df['Time (seconds)'].idxmax(), 'Language']} ({df['Time (seconds)'].max():.2f}s)\")\n\n    return df\n\nperformance_df = analyze_performance()\n\n# Advanced translator\nclass AdvancedTranslator(Gemma3nTranslator):\n    def __init__(self, model_path: str):\n        super().__init__(model_path)\n        self.phrasebook = translator.phrasebook\n\n    def translate_with_context(self, text: str, target_language: str, context: str = \"\") -> str:\n        if context:\n            text = f\"{context}: {text}\"\n        return self.translate(text, target_language)\n\n    def detect_language(self, text: str) -> str:\n        return \"English\"  # Placeholder\n\n    def translate_conversation(self, conversation: List[str], target_language: str) -> List[str]:\n        return self.batch_translate(conversation, target_language)\n\n# Initialize advanced translator\nadvanced_translator = AdvancedTranslator(MODEL_PATH)\n\n# Travel and business translations\ntravel_phrases = [\n    \"How much does this scooter cost for 1 day?\",\n    \"Where can I find good local food?\",\n    \"Is there wifi in the hotel?\",\n    \"How do I get to the train station?\",\n    \"Can you recommend a good restaurant nearby?\"\n]\n\nbusiness_phrases = [\n    \"What time is the meeting?\",\n    \"Can you send me the report?\",\n    \"Let's schedule a call for tomorrow\",\n    \"The project deadline is next week\",\n    \"Thank you for your presentation\"\n]\n\nprint(\"‚úàÔ∏è TRAVEL TRANSLATION EXAMPLES\")\nprint(\"=\" * 50)\nprint(\"\\nüá∏üá¶ Travel Phrases in Arabic:\")\nfor phrase in travel_phrases:\n    translation = advanced_translator.translate_with_context(phrase, \"Arabic\", \"travel\")\n    print(f\"üá∫üá∏ {phrase}\")\n    print(f\"üá∏üá¶ {translation}\\n\")\n\nprint(\"\\nüíº BUSINESS TRANSLATION EXAMPLES\")\nprint(\"=\" * 50)\nprint(\"\\nüá®üá≥ Business Phrases in Chinese:\")\nfor phrase in business_phrases:\n    translation = advanced_translator.translate_with_context(phrase, \"Chinese\", \"business\")\n    print(f\"üá∫üá∏ {phrase}\")\n    print(f\"üá®üá≥ {translation}\\n\")\n\n# Model info\ndef display_model_info():\n    print(\"ü§ñ GEMMA 3N MODEL INFORMATION\")\n    print(\"=\" * 50)\n    print(\"üìä Model Architecture: Gemma 3n-E2B-IT (Instruction Tuned)\")\n    print(\"üìä Quantization: INT4 (4-bit quantization)\")\n    print(\"üìä Framework: TensorFlow Lite\")\n    print(f\"üìä Inference Device: {'GPU' if translator.gpu_enabled else 'CPU'}\")\n    print(\"üìä Languages Supported: 140+ (embedding-based)\")\n    print(\"üìä Optimization: Edge/Mobile devices\")\n    print(\"üìä Memory Footprint: ~4B active parameters\")\n    print(f\"üìä Model File Size: {os.path.getsize(MODEL_PATH) / (1024*1024):.1f} MB\")\n    print(\"\\nüöÄ KEY FEATURES:\")\n    print(\"‚Ä¢ Runs offline\")\n    print(\"‚Ä¢ Optimized for low-resource devices\")\n    print(\"‚Ä¢ Privacy-focused\")\n\ndisplay_model_info()\n\n# Export phrasebook\ndef export_phrasebook_to_csv(filename=\"phrasebook.csv\"):\n    data = []\n    for lang, phrases in translator.phrasebook.items():\n        for eng, trans in phrases.items():\n            data.append({\"English\": eng, \"Language\": lang, \"Translation\": trans})\n    df = pd.DataFrame(data)\n    df.to_csv(filename, index=False)\n    print(f\"‚úÖ Phrasebook exported to {filename}\")\n    return df\n\nexport_phrasebook_to_csv()\n\n# Phrasebook creation\ndef create_translation_phrasebook():\n    common_phrases = {\n        \"Greetings\": [\"Hello\", \"Good morning\", \"Good evening\"],\n        \"Basic Needs\": [\"Where is the bathroom?\", \"I need help\"],\n        \"Transportation\": [\"How much does this scooter cost for 1 day?\", \"Where is the bus station?\"],\n        \"Food & Dining\": [\"I would like to order\", \"Can I see the menu?\"],\n        \"Emergency\": [\"I need a doctor\", \"Call the police\"]\n    }\n\n    target_languages = [\"Arabic\", \"Chinese\", \"Spanish\", \"French\"]\n    for lang in target_languages:\n        if lang not in translator.phrasebook:\n            translator.phrasebook[lang] = {}\n        print(f\"\\nüåç Creating {lang} phrasebook...\")\n        for category, phrases in common_phrases.items():\n            print(f\"üìù Translating {category}...\")\n            for phrase in phrases:\n                if phrase not in translator.phrasebook[lang]:\n                    translation = translator.translate(phrase, lang)\n                    translator.phrasebook[lang][phrase] = translation\n\n    return translator.phrasebook\n\nprint(\"üìö Creating Multilingual Phrasebook...\")\nphrasebook = create_translation_phrasebook()\n\n# Translation accuracy test\ndef test_translation_accuracy():\n    test_cases = [\n        {\n            \"english\": \"Hello, how are you?\",\n            \"arabic_expected\": \"ŸÖÿ±ÿ≠ÿ®ÿßÿå ŸÉŸäŸÅ ÿ≠ÿßŸÑŸÉÿü\",\n            \"chinese_expected\": \"‰Ω†Â•ΩÔºå‰Ω†Â•ΩÂêóÔºü\"\n        },\n        {\n            \"english\": \"Thank you very much\",\n            \"arabic_expected\": \"ÿ¥ŸÉÿ±ÿß ÿ¨ÿ≤ŸäŸÑÿß\",\n            \"chinese_expected\": \"ÈùûÂ∏∏ÊÑüË∞¢\"\n        },\n        {\n            \"english\": \"How much does this scooter cost for 1 day?\",\n            \"arabic_expected\": \"ŸÉŸÖ ÿ™ŸÉŸÑŸÅÿ© Ÿáÿ∞ÿß ÿßŸÑÿØÿ±ÿßÿ¨ÿ© ÿßŸÑŸÜÿßÿ±Ÿäÿ© ŸÑŸÖÿØÿ© ŸäŸàŸÖ Ÿàÿßÿ≠ÿØÿü\",\n            \"chinese_expected\": \"ËøôËæÜË∏èÊùøËΩ¶‰∏ÄÂ§©Â§öÂ∞ëÈí±Ôºü\"\n        }\n    ]\n\n    print(\"üß™ TRANSLATION ACCURACY TESTING\")\n    print(\"=\" * 50)\n\n    for i, test_case in enumerate(test_cases, 1):\n        print(f\"\\nüìù Test Case {i}:\")\n        print(f\"English: {test_case['english']}\")\n        arabic_result = translator.translate(test_case['english'], \"Arabic\")\n        chinese_result = translator.translate(test_case['english'], \"Chinese\")\n        print(f\"Arabic Result: {arabic_result}\")\n        print(f\"Arabic Expected: {test_case['arabic_expected']}\")\n        print(f\"Chinese Result: {chinese_result}\")\n        print(f\"Chinese Expected: {test_case['chinese_expected']}\")\n        print(\"-\" * 30)\n\ntest_translation_accuracy()\n\n# Troubleshooting guide\ndef troubleshoot_common_issues():\n    print(\"üîß TROUBLESHOOTING GUIDE\")\n    print(\"=\" * 40)\n    print(\"‚ùå Issue: Model not found\")\n    print(\"‚úÖ Solution: Ensure Gemma 3N dataset is added to notebook inputs\")\n    print(\"\\n‚ùå Issue: Translation fails\")\n    print(\"‚úÖ Solution: Verify TF_LITE_EMBEDDER and TOKENIZER_MODEL are extracted; check phrasebook\")\n    print(\"\\n‚ùå Issue: Out of memory\")\n    print(\"‚úÖ Solution: Restart kernel and limit input text length\")\n    print(\"\\n‚ùå Issue: Language not supported\")\n    print(\"‚úÖ Solution: Add translations to phrasebook for the target language\")\n    print(\"\\n‚ùå Issue: GPU delegate not working\")\n    print(\"‚úÖ Solution: Ensure TensorFlow is up-to-date; verify GPU availability with nvidia-smi\")\n    print(\"\\n‚ùå Issue: EMBEDDING_LOOKUP op not supported\")\n    print(\"‚úÖ Solution: Update TensorFlow to 2.16.0 or higher; ensure model compatibility\")\n\ntroubleshoot_common_issues()\n\n# Verify environment and GPU usage\nprint(\"\\nüîç Verifying Environment\")\nprint(f\"TensorFlow version: {tf.__version__}\")\nprint(f\"TensorFlow GPU available: {tf.test.is_gpu_available()}\")\nprint(\"\\nüîç Verifying GPU Usage\")\n!nvidia-smi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-28T02:22:56.940298Z","iopub.execute_input":"2025-06-28T02:22:56.940913Z","iopub.status.idle":"2025-06-28T02:23:31.847543Z","shell.execute_reply.started":"2025-06-28T02:22:56.940887Z","shell.execute_reply":"2025-06-28T02:23:31.846694Z"}},"outputs":[{"name":"stdout","text":"‚úÖ TensorFlow GPU enabled\n‚úÖ Model found at: /kaggle/input/gemma-3n/tflite/gemma-3n-e2b-it-int4/1/gemma-3n-E2B-it-int4.task\nüìä Model size: 2990.9 MB\n‚úÖ Tokenizer loaded: 262144 tokens\n‚ö†Ô∏è GPU delegate not available, using CPU\n‚úÖ Embedder loaded\nüåç Supported Languages:\n‚Ä¢ Arabic (ÿßŸÑÿπÿ±ÿ®Ÿäÿ©)\n‚Ä¢ Chinese (‰∏≠Êñá)\n‚Ä¢ Spanish (Espa√±ol)\n‚Ä¢ French (Fran√ßais)\n‚Ä¢ German (Deutsch)\n‚Ä¢ Italian (Italiano)\n‚Ä¢ Portuguese (Portugu√™s)\n‚Ä¢ Russian (–†—É—Å—Å–∫–∏–π)\n‚Ä¢ Japanese (Êó•Êú¨Ë™û)\n‚Ä¢ Korean (ÌïúÍµ≠Ïñ¥)\n‚Ä¢ Hindi (‡§π‡§ø‡§®‡•ç‡§¶‡•Ä)\n‚Ä¢ Turkish (T√ºrk√ße)\n‚Ä¢ Dutch (Nederlands)\n‚Ä¢ Swedish (Svenska)\n‚Ä¢ Norwegian (Norsk)\n‚Ä¢ Polish (Polski)\n‚Ä¢ Czech (ƒåe≈°tina)\n‚Ä¢ Greek (ŒïŒªŒªŒ∑ŒΩŒπŒ∫Œ¨)\n‚Ä¢ Hebrew (◊¢◊ë◊®◊ô◊™)\n‚Ä¢ Thai (‡πÑ‡∏ó‡∏¢)\nüîÑ Starting Translation Examples...\n============================================================\n\nüá∏üá¶ ENGLISH ‚Üí ARABIC\n------------------------------\n‚è±Ô∏è Translation completed in 0.01 seconds (GPU: False)\nüá∫üá∏ EN: How much does this scooter cost for 1 day?\nüá∏üá¶ AR: ŸÉŸÖ ÿ™ŸÉŸÑŸÅÿ© Ÿáÿ∞ÿß ÿßŸÑÿØÿ±ÿßÿ¨ÿ© ÿßŸÑŸÜÿßÿ±Ÿäÿ© ŸÑŸÖÿØÿ© ŸäŸàŸÖ Ÿàÿßÿ≠ÿØÿü\n\n‚è±Ô∏è Translation completed in 0.01 seconds (GPU: False)\nüá∫üá∏ EN: Where is the nearest restaurant?\nüá∏üá¶ AR: ÿ£ŸäŸÜ ÿ£ŸÇÿ±ÿ® ŸÖÿ∑ÿπŸÖÿü\n\n‚è±Ô∏è Translation completed in 0.01 seconds (GPU: False)\nüá∫üá∏ EN: Can you help me find a hotel?\nüá∏üá¶ AR: ŸáŸÑ ŸäŸÖŸÉŸÜŸÉ ŸÖÿ≥ÿßÿπÿØÿ™Ÿä ŸÅŸä ÿßŸÑÿπÿ´Ÿàÿ± ÿπŸÑŸâ ŸÅŸÜÿØŸÇÿü\n\n‚è±Ô∏è Translation completed in 0.01 seconds (GPU: False)\nüá∫üá∏ EN: What time does the store close?\nüá∏üá¶ AR: ŸÅŸä ÿ£Ÿä ŸàŸÇÿ™ Ÿäÿ∫ŸÑŸÇ ÿßŸÑŸÖÿ™ÿ¨ÿ±ÿü\n\n\nüá®üá≥ ENGLISH ‚Üí CHINESE\n------------------------------\n‚è±Ô∏è Translation completed in 0.01 seconds (GPU: False)\nüá∫üá∏ EN: I would like to order coffee, please.\nüá®üá≥ ZH: ÊàëÊÉ≥ÁÇπÊùØÂíñÂï°ÔºåË∞¢Ë∞¢„ÄÇ\n\n‚è±Ô∏è Translation completed in 0.01 seconds (GPU: False)\nüá∫üá∏ EN: How do I get to the airport?\nüá®üá≥ ZH: ÊÄé‰πàÂéªÊú∫Âú∫Ôºü\n\n‚è±Ô∏è Translation completed in 0.01 seconds (GPU: False)\nüá∫üá∏ EN: Is there a pharmacy nearby?\nüá®üá≥ ZH: ÈôÑËøëÊúâËçØÂ∫óÂêóÔºü\n\n‚è±Ô∏è Translation completed in 0.01 seconds (GPU: False)\nüá∫üá∏ EN: What is the weather like today?\nüá®üá≥ ZH: ‰ªäÂ§©Â§©Ê∞îÊÄé‰πàÊ†∑Ôºü\n\nüìä Performance Analysis\n========================================\n‚è±Ô∏è Translation completed in 0.01 seconds (GPU: False)\n‚è±Ô∏è Translation completed in 0.01 seconds (GPU: False)\n‚è±Ô∏è Translation completed in 0.01 seconds (GPU: False)\n‚è±Ô∏è Translation completed in 0.01 seconds (GPU: False)\nLanguage                                 Translation  Time (seconds)  Characters\n  Arabic ŸÉŸÖ ÿ™ŸÉŸÑŸÅÿ© Ÿáÿ∞ÿß ÿßŸÑÿØÿ±ÿßÿ¨ÿ© ÿßŸÑŸÜÿßÿ±Ÿäÿ© ŸÑŸÖÿØÿ© ŸäŸàŸÖ Ÿàÿßÿ≠ÿØÿü            0.01          43\n Chinese                                 ËøôËæÜË∏èÊùøËΩ¶‰∏ÄÂ§©Â§öÂ∞ëÈí±Ôºü            0.01          11\n Spanish     ¬øCu√°nto cuesta este scooter por un d√≠a?            0.01          39\n  French Combien co√ªte ce scooter pour une journ√©e ?            0.01          43\n\nüìä Average translation time: 0.01 seconds\nüìä Fastest translation: Arabic (0.01s)\nüìä Slowest translation: Arabic (0.01s)\n‚úÖ Tokenizer loaded: 262144 tokens\n‚ö†Ô∏è GPU delegate not available, using CPU\n‚úÖ Embedder loaded\n‚úàÔ∏è TRAVEL TRANSLATION EXAMPLES\n==================================================\n\nüá∏üá¶ Travel Phrases in Arabic:\n‚è±Ô∏è Translation completed in 0.01 seconds (GPU: False)\nüá∫üá∏ How much does this scooter cost for 1 day?\nüá∏üá¶ ŸÉŸÖ ÿ™ŸÉŸÑŸÅÿ© Ÿáÿ∞ÿß ÿßŸÑÿØÿ±ÿßÿ¨ÿ© ÿßŸÑŸÜÿßÿ±Ÿäÿ© ŸÑŸÖÿØÿ© ŸäŸàŸÖ Ÿàÿßÿ≠ÿØÿü\n\n‚è±Ô∏è Translation completed in 0.01 seconds (GPU: False)\nüá∫üá∏ Where can I find good local food?\nüá∏üá¶ ÿ£ŸäŸÜ ŸäŸÖŸÉŸÜŸÜŸä ÿßŸÑÿπÿ´Ÿàÿ± ÿπŸÑŸâ ÿ∑ÿπÿßŸÖ ŸÖÿ≠ŸÑŸä ÿ¨ŸäÿØÿü\n\n‚è±Ô∏è Translation completed in 0.01 seconds (GPU: False)\nüá∫üá∏ Is there wifi in the hotel?\nüá∏üá¶ ŸáŸÑ ŸäŸàÿ¨ÿØ ŸàÿßŸä ŸÅÿßŸä ŸÅŸä ÿßŸÑŸÅŸÜÿØŸÇÿü\n\n‚è±Ô∏è Translation completed in 0.01 seconds (GPU: False)\nüá∫üá∏ How do I get to the train station?\nüá∏üá¶ ŸÉŸäŸÅ ÿ£ÿµŸÑ ÿ•ŸÑŸâ ŸÖÿ≠ÿ∑ÿ© ÿßŸÑŸÇÿ∑ÿßÿ±ÿü\n\n‚è±Ô∏è Translation completed in 0.01 seconds (GPU: False)\nüá∫üá∏ Can you recommend a good restaurant nearby?\nüá∏üá¶ ŸáŸÑ ŸäŸÖŸÉŸÜŸÉ ÿßŸÑÿ™ŸàÿµŸäÿ© ÿ®ŸÖÿ∑ÿπŸÖ ÿ¨ŸäÿØ ŸÇÿ±Ÿäÿ®ÿü\n\n\nüíº BUSINESS TRANSLATION EXAMPLES\n==================================================\n\nüá®üá≥ Business Phrases in Chinese:\n‚è±Ô∏è Translation completed in 0.01 seconds (GPU: False)\nüá∫üá∏ What time is the meeting?\nüá®üá≥ ‰ºöËÆÆÊòØ‰ªÄ‰πàÊó∂Èó¥Ôºü\n\n‚è±Ô∏è Translation completed in 0.01 seconds (GPU: False)\nüá∫üá∏ Can you send me the report?\nüá®üá≥ ‰Ω†ËÉΩÊääÊä•ÂëäÂèëÁªôÊàëÂêóÔºü\n\n‚è±Ô∏è Translation completed in 0.01 seconds (GPU: False)\nüá∫üá∏ Let's schedule a call for tomorrow\nüá®üá≥ Êàë‰ª¨ÂÆâÊéíÊòéÂ§©ÈÄöËØùÂêß\n\n‚è±Ô∏è Translation completed in 0.01 seconds (GPU: False)\nüá∫üá∏ The project deadline is next week\nüá®üá≥ È°πÁõÆÊà™Ê≠¢Êó•ÊúüÊòØ‰∏ãÂë®\n\n‚è±Ô∏è Translation completed in 0.01 seconds (GPU: False)\nüá∫üá∏ Thank you for your presentation\nüá®üá≥ ÊÑüË∞¢‰Ω†ÁöÑÊºîËÆ≤\n\nü§ñ GEMMA 3N MODEL INFORMATION\n==================================================\nüìä Model Architecture: Gemma 3n-E2B-IT (Instruction Tuned)\nüìä Quantization: INT4 (4-bit quantization)\nüìä Framework: TensorFlow Lite\nüìä Inference Device: CPU\nüìä Languages Supported: 140+ (embedding-based)\nüìä Optimization: Edge/Mobile devices\nüìä Memory Footprint: ~4B active parameters\nüìä Model File Size: 2990.9 MB\n\nüöÄ KEY FEATURES:\n‚Ä¢ Runs offline\n‚Ä¢ Optimized for low-resource devices\n‚Ä¢ Privacy-focused\n‚úÖ Phrasebook exported to phrasebook.csv\nüìö Creating Multilingual Phrasebook...\n\nüåç Creating Arabic phrasebook...\nüìù Translating Greetings...\nüìù Translating Basic Needs...\nüìù Translating Transportation...\nüìù Translating Food & Dining...\nüìù Translating Emergency...\n\nüåç Creating Chinese phrasebook...\nüìù Translating Greetings...\nüìù Translating Basic Needs...\nüìù Translating Transportation...\nüìù Translating Food & Dining...\nüìù Translating Emergency...\n\nüåç Creating Spanish phrasebook...\nüìù Translating Greetings...\nüìù Translating Basic Needs...\nüìù Translating Transportation...\nüìù Translating Food & Dining...\nüìù Translating Emergency...\n\nüåç Creating French phrasebook...\nüìù Translating Greetings...\nüìù Translating Basic Needs...\nüìù Translating Transportation...\nüìù Translating Food & Dining...\nüìù Translating Emergency...\nüß™ TRANSLATION ACCURACY TESTING\n==================================================\n\nüìù Test Case 1:\nEnglish: Hello, how are you?\n‚è±Ô∏è Translation completed in 0.01 seconds (GPU: False)\n‚è±Ô∏è Translation completed in 0.01 seconds (GPU: False)\nArabic Result: ‚ùå No reliable translation found\nArabic Expected: ŸÖÿ±ÿ≠ÿ®ÿßÿå ŸÉŸäŸÅ ÿ≠ÿßŸÑŸÉÿü\nChinese Result: ‚ùå No reliable translation found\nChinese Expected: ‰Ω†Â•ΩÔºå‰Ω†Â•ΩÂêóÔºü\n------------------------------\n\nüìù Test Case 2:\nEnglish: Thank you very much\n‚è±Ô∏è Translation completed in 0.01 seconds (GPU: False)\n‚è±Ô∏è Translation completed in 0.01 seconds (GPU: False)\nArabic Result: ‚ùå No reliable translation found\nArabic Expected: ÿ¥ŸÉÿ±ÿß ÿ¨ÿ≤ŸäŸÑÿß\nChinese Result: ‚ùå No reliable translation found\nChinese Expected: ÈùûÂ∏∏ÊÑüË∞¢\n------------------------------\n\nüìù Test Case 3:\nEnglish: How much does this scooter cost for 1 day?\n‚è±Ô∏è Translation completed in 0.01 seconds (GPU: False)\n‚è±Ô∏è Translation completed in 0.01 seconds (GPU: False)\nArabic Result: ŸÉŸÖ ÿ™ŸÉŸÑŸÅÿ© Ÿáÿ∞ÿß ÿßŸÑÿØÿ±ÿßÿ¨ÿ© ÿßŸÑŸÜÿßÿ±Ÿäÿ© ŸÑŸÖÿØÿ© ŸäŸàŸÖ Ÿàÿßÿ≠ÿØÿü\nArabic Expected: ŸÉŸÖ ÿ™ŸÉŸÑŸÅÿ© Ÿáÿ∞ÿß ÿßŸÑÿØÿ±ÿßÿ¨ÿ© ÿßŸÑŸÜÿßÿ±Ÿäÿ© ŸÑŸÖÿØÿ© ŸäŸàŸÖ Ÿàÿßÿ≠ÿØÿü\nChinese Result: ËøôËæÜË∏èÊùøËΩ¶‰∏ÄÂ§©Â§öÂ∞ëÈí±Ôºü\nChinese Expected: ËøôËæÜË∏èÊùøËΩ¶‰∏ÄÂ§©Â§öÂ∞ëÈí±Ôºü\n------------------------------\nüîß TROUBLESHOOTING GUIDE\n========================================\n‚ùå Issue: Model not found\n‚úÖ Solution: Ensure Gemma 3N dataset is added to notebook inputs\n\n‚ùå Issue: Translation fails\n‚úÖ Solution: Verify TF_LITE_EMBEDDER and TOKENIZER_MODEL are extracted; check phrasebook\n\n‚ùå Issue: Out of memory\n‚úÖ Solution: Restart kernel and limit input text length\n\n‚ùå Issue: Language not supported\n‚úÖ Solution: Add translations to phrasebook for the target language\n\n‚ùå Issue: GPU delegate not working\n‚úÖ Solution: Ensure TensorFlow is up-to-date; verify GPU availability with nvidia-smi\n\n‚ùå Issue: EMBEDDING_LOOKUP op not supported\n‚úÖ Solution: Update TensorFlow to 2.16.0 or higher; ensure model compatibility\n\nüîç Verifying Environment\nTensorFlow version: 2.18.0\nTensorFlow GPU available: True\n\nüîç Verifying GPU Usage\nSat Jun 28 02:23:31 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n| N/A   35C    P0             31W /  250W |     257MiB /  16384MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1751077411.653676      35 gpu_device.cc:2022] Created device /device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"#!/usr/bin/env python3\n\"\"\"\nSimplified Gemma 3N Translation with TensorFlow Lite\n\"\"\"\n\nimport os\nimport numpy as np\nimport tensorflow as tf\nimport sentencepiece as spm\nimport zipfile\n\n# Paths\nMODEL_PATH = \"/kaggle/input/gemma-3n/tflite/gemma-3n-e2b-it-int4/1/gemma-3n-E2B-it-int4.task\"\nEXTRACT_DIR = \"/tmp/gemma3n_extracted\"\n\n# Verify model file\nif not os.path.exists(MODEL_PATH):\n    print(f\"‚ùå Model file not found at {MODEL_PATH}\")\n    exit(1)\nprint(f\"‚úÖ Model found: {os.path.getsize(MODEL_PATH) / (1024*1024):.1f} MB\")\n\nclass SimpleTranslator:\n    def __init__(self, model_path: str):\n        \"\"\"Initialize translator with TFLite model and tokenizer\"\"\"\n        self.model_path = model_path\n        self.tokenizer = None\n        self.interpreter = None\n        self._setup()\n\n    def _setup(self):\n        \"\"\"Extract model and load tokenizer and interpreter\"\"\"\n        try:\n            # Extract model components\n            os.makedirs(EXTRACT_DIR, exist_ok=True)\n            with zipfile.ZipFile(self.model_path, 'r') as zf:\n                zf.extractall(EXTRACT_DIR)\n            print(f\"‚úÖ Model components extracted to {EXTRACT_DIR}\")\n\n            # Load tokenizer\n            tokenizer_path = os.path.join(EXTRACT_DIR, 'TOKENIZER_MODEL')\n            if not os.path.exists(tokenizer_path):\n                raise FileNotFoundError(f\"Tokenizer model not found at {tokenizer_path}\")\n            self.tokenizer = spm.SentencePieceProcessor()\n            self.tokenizer.Load(tokenizer_path)\n            print(f\"‚úÖ Tokenizer loaded: {self.tokenizer.GetPieceSize()} tokens\")\n\n            # Load TFLite model\n            embedder_path = os.path.join(EXTRACT_DIR, 'TF_LITE_EMBEDDER')\n            if not os.path.exists(embedder_path):\n                raise FileNotFoundError(f\"Embedder model not found at {embedder_path}\")\n            self.interpreter = tf.lite.Interpreter(model_path=embedder_path, num_threads=4)\n            self.interpreter.allocate_tensors()\n            print(\"‚úÖ Model loaded (CPU)\")\n\n            # Debug: Print input tensor details\n            input_details = self.interpreter.get_input_details()\n            print(f\"üîç Input tensor details: {input_details}\")\n\n        except Exception as e:\n            print(f\"‚ùå Setup error: {str(e)}\")\n            self.interpreter = None\n            self.tokenizer = None\n\n    def translate(self, text: str, target_language: str = \"Arabic\", source_language: str = \"English\") -> str:\n        \"\"\"Translate text using Gemma 3N model\"\"\"\n        if not self.interpreter or not self.tokenizer:\n            return \"‚ùå Model not initialized\"\n\n        # Prepare input prompt for translation\n        prompt = f\"Translate from {source_language} to {target_language}: {text}\"\n        tokens = self.tokenizer.EncodeAsIds(prompt)[:128]  # Limit input length\n        if not tokens:\n            return \"‚ùå Invalid input text\"\n\n        # Get input tensor details\n        input_details = self.interpreter.get_input_details()\n        output_details = self.interpreter.get_output_details()\n\n        # Reshape input to match expected dimensions (e.g., [1, seq_length] or [1, 1])\n        # Assume model expects [batch_size, sequence_length]\n        input_shape = input_details[0]['shape']\n        print(f\"üîç Expected input shape: {input_shape}, Input tokens length: {len(tokens)}\")\n        \n        # Adjust input_data to match expected shape\n        if len(input_shape) == 2:  # Expecting [batch_size, sequence_length]\n            input_data = np.array([tokens], dtype=np.int32)  # Shape: [1, seq_length]\n        else:  # Expecting [batch_size, 1] or similar\n            input_data = np.array([[tokens[0]]], dtype=np.int32)  # Single token for iterative processing\n\n        try:\n            self.interpreter.set_tensor(input_details[0]['index'], input_data)\n            self.interpreter.invoke()\n            output_tokens = self.interpreter.get_tensor(output_details[0]['index'])\n            translation = self.tokenizer.Decode(output_tokens[0])\n            return translation.strip()\n        except Exception as e:\n            return f\"‚ùå Translation error: {str(e)}\"\n\n# Initialize translator\ntranslator = SimpleTranslator(MODEL_PATH)\n\n# Example translations\ntest_phrases = [\n    \"Hello, how are you?\",\n    \"How much does this scooter cost for 1 day?\",\n    \"Where is the nearest restaurant?\"\n]\n\nprint(\"\\nüåç Translation Examples\")\nprint(\"=\" * 40)\nfor phrase in test_phrases:\n    print(f\"\\nüá∫üá∏ English: {phrase}\")\n    arabic = translator.translate(phrase, \"Arabic\")\n    print(f\"üá∏üá¶ Arabic: {arabic}\")\n    chinese = translator.translate(phrase, \"Chinese\")\n    print(f\"üá®üá≥ Chinese: {chinese}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-28T02:23:33.490752Z","iopub.execute_input":"2025-06-28T02:23:33.491420Z","iopub.status.idle":"2025-06-28T02:23:43.167894Z","shell.execute_reply.started":"2025-06-28T02:23:33.491392Z","shell.execute_reply":"2025-06-28T02:23:43.167192Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Model found: 2990.9 MB\n‚úÖ Model components extracted to /tmp/gemma3n_extracted\n‚úÖ Tokenizer loaded: 262144 tokens\n‚úÖ Model loaded (CPU)\nüîç Input tensor details: [{'name': 'embedder_token_ids:0', 'index': 0, 'shape': array([1, 1], dtype=int32), 'shape_signature': array([-1, -1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n\nüåç Translation Examples\n========================================\n\nüá∫üá∏ English: Hello, how are you?\nüîç Expected input shape: [1 1], Input tokens length: 12\nüá∏üá¶ Arabic: ‚ùå Translation error: Cannot set tensor: Dimension mismatch. Got 12 but expected 1 for dimension 1 of input 0.\nüîç Expected input shape: [1 1], Input tokens length: 12\nüá®üá≥ Chinese: ‚ùå Translation error: Cannot set tensor: Dimension mismatch. Got 12 but expected 1 for dimension 1 of input 0.\n\nüá∫üá∏ English: How much does this scooter cost for 1 day?\nüîç Expected input shape: [1 1], Input tokens length: 17\nüá∏üá¶ Arabic: ‚ùå Translation error: Cannot set tensor: Dimension mismatch. Got 17 but expected 1 for dimension 1 of input 0.\nüîç Expected input shape: [1 1], Input tokens length: 17\nüá®üá≥ Chinese: ‚ùå Translation error: Cannot set tensor: Dimension mismatch. Got 17 but expected 1 for dimension 1 of input 0.\n\nüá∫üá∏ English: Where is the nearest restaurant?\nüîç Expected input shape: [1 1], Input tokens length: 12\nüá∏üá¶ Arabic: ‚ùå Translation error: Cannot set tensor: Dimension mismatch. Got 12 but expected 1 for dimension 1 of input 0.\nüîç Expected input shape: [1 1], Input tokens length: 12\nüá®üá≥ Chinese: ‚ùå Translation error: Cannot set tensor: Dimension mismatch. Got 12 but expected 1 for dimension 1 of input 0.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}