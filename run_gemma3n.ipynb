{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":397953,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":326098,"modelId":317146}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install tflite-runtime","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-28T02:12:02.771202Z","iopub.execute_input":"2025-06-28T02:12:02.771504Z","iopub.status.idle":"2025-06-28T02:12:07.116840Z","shell.execute_reply.started":"2025-06-28T02:12:02.771480Z","shell.execute_reply":"2025-06-28T02:12:07.115963Z"}},"outputs":[{"name":"stdout","text":"Collecting tflite-runtime\n  Downloading tflite_runtime-2.14.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.4 kB)\nRequirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from tflite-runtime) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->tflite-runtime) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->tflite-runtime) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->tflite-runtime) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->tflite-runtime) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->tflite-runtime) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->tflite-runtime) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->tflite-runtime) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->tflite-runtime) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.2->tflite-runtime) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.2->tflite-runtime) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.2->tflite-runtime) (2024.2.0)\nDownloading tflite_runtime-2.14.0-cp311-cp311-manylinux2014_x86_64.whl (2.4 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: tflite-runtime\nSuccessfully installed tflite-runtime-2.14.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"#!/usr/bin/env python3\n\"\"\"\nGemma 3N Translation Notebook - Embedding-Based Fallback with GPU Support\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport sentencepiece as spm\nimport zipfile\nimport time\nfrom typing import Dict, List\n\n# Ensure GPU is used if available\nphysical_devices = tf.config.list_physical_devices('GPU')\nif physical_devices:\n    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n    print(\"âœ… TensorFlow GPU enabled\")\nelse:\n    print(\"âš ï¸ GPU not detected, using CPU\")\n\n# Path to the Gemma 3N model file\nMODEL_PATH = \"/kaggle/input/gemma-3n/tflite/gemma-3n-e2b-it-int4/1/gemma-3n-E2B-it-int4.task\"\nEXTRACT_DIR = \"/tmp/gemma3n_extracted\"\n\n# Verify model file exists\nif os.path.exists(MODEL_PATH):\n    print(f\"âœ… Model found at: {MODEL_PATH}\")\n    print(f\"ğŸ“Š Model size: {os.path.getsize(MODEL_PATH) / (1024*1024):.1f} MB\")\nelse:\n    print(\"âŒ Model file not found. Please ensure the dataset is properly added.\")\n    exit(1)\n\nclass Gemma3nTranslator:\n    def __init__(self, model_path: str):\n        \"\"\"Initialize the Gemma 3N translator with TFLite and SentencePiece\"\"\"\n        self.model_path = model_path\n        self.tokenizer = None\n        self.embedder = None\n        self.phrasebook = {}\n        self.gpu_enabled = False\n        self._setup()\n\n    def _setup(self):\n        \"\"\"Setup tokenizer and embedder with GPU delegate if available\"\"\"\n        try:\n            # Extract model components\n            os.makedirs(EXTRACT_DIR, exist_ok=True)\n            with zipfile.ZipFile(self.model_path, 'r') as zf:\n                zf.extractall(EXTRACT_DIR)\n\n            # Load tokenizer\n            tokenizer_path = os.path.join(EXTRACT_DIR, 'TOKENIZER_MODEL')\n            if os.path.exists(tokenizer_path):\n                self.tokenizer = spm.SentencePieceProcessor()\n                self.tokenizer.Load(tokenizer_path)\n                print(f\"âœ… Tokenizer loaded: {self.tokenizer.GetPieceSize()} tokens\")\n            else:\n                raise FileNotFoundError(\"Tokenizer model not found\")\n\n            # Load embedder with GPU delegate\n            embedder_path = os.path.join(EXTRACT_DIR, 'TF_LITE_EMBEDDER')\n            if os.path.exists(embedder_path):\n                try:\n                    # Attempt to load GPU delegate\n                    # Note: Kaggle may not have libtflite_gpu_delegate.so; try CPU fallback\n                    delegate = None\n                    if os.path.exists('/usr/lib/libtflite_gpu_delegate.so'):\n                        delegate = tf.lite.experimental.delegates.Delegate(\n                            library='libtflite_gpu_delegate.so'\n                        )\n                    self.embedder = tf.lite.Interpreter(\n                        model_path=embedder_path,\n                        experimental_delegates=[delegate] if delegate else []\n                    )\n                    self.gpu_enabled = bool(delegate)\n                    print(\"âœ… TFLite GPU delegate enabled\" if self.gpu_enabled else \"âš ï¸ GPU delegate not available, using CPU\")\n                except Exception as e:\n                    print(f\"âš ï¸ GPU delegate failed: {str(e)}. Falling back to CPU.\")\n                    self.embedder = tf.lite.Interpreter(model_path=embedder_path, num_threads=4)\n                    self.gpu_enabled = False\n                self.embedder.allocate_tensors()\n                print(\"âœ… Embedder loaded\")\n            else:\n                raise FileNotFoundError(\"Embedder model not found\")\n\n        except Exception as e:\n            print(f\"âŒ Setup error: {str(e)}. Translation will not work until resolved.\")\n            self.embedder = None\n\n    def _get_embedding(self, text: str) -> np.ndarray:\n        \"\"\"Get average embedding for text\"\"\"\n        if not self.embedder or not self.tokenizer:\n            return np.zeros(2048)\n\n        tokens = self.tokenizer.EncodeAsIds(text)[:50]\n        if not tokens:\n            return np.zeros(2048)\n\n        input_details = self.embedder.get_input_details()\n        output_details = self.embedder.get_output_details()\n        embeddings = []\n\n        for token_id in tokens:\n            input_data = np.array([[token_id]], dtype=np.int32)\n            self.embedder.set_tensor(input_details[0]['index'], input_data)\n            self.embedder.invoke()\n            embedding = self.embedder.get_tensor(output_details[0]['index'])\n            embeddings.append(embedding[0, 0, :])\n\n        return np.mean(embeddings, axis=0)\n\n    def translate(self, text: str, target_language: str = \"Arabic\", source_language: str = \"English\") -> str:\n        \"\"\"Translate text using embedding-based similarity\"\"\"\n        if not self.embedder or not self.tokenizer:\n            return \"âŒ Model not initialized\"\n        if target_language not in self.phrasebook:\n            return f\"âŒ No phrasebook for {target_language}\"\n\n        start_time = time.time()\n        input_emb = self._get_embedding(text)\n        if np.all(input_emb == 0):\n            return \"âŒ Invalid input text\"\n\n        best_match = None\n        best_sim = -1\n\n        for eng, trans in self.phrasebook[target_language].items():\n            eng_emb = self._get_embedding(eng)\n            if np.all(eng_emb == 0):\n                continue\n            sim = np.dot(input_emb, eng_emb) / (max(np.linalg.norm(input_emb) * np.linalg.norm(eng_emb), 1e-10))\n            if sim > best_sim:\n                best_sim = sim\n                best_match = trans\n\n        end_time = time.time()\n        print(f\"â±ï¸ Translation completed in {end_time - start_time:.2f} seconds (GPU: {self.gpu_enabled})\")\n        if best_sim < 0.8:\n            return \"âŒ No reliable translation found\"\n        return best_match or \"âŒ No matching translation found\"\n\n    def batch_translate(self, texts: List[str], target_language: str = \"Arabic\") -> List[str]:\n        \"\"\"Translate multiple texts\"\"\"\n        translations = []\n        for i, text in enumerate(texts):\n            print(f\"Translating {i+1}/{len(texts)}: {text[:50]}...\")\n            translation = self.translate(text, target_language)\n            translations.append(translation)\n        return translations\n\n# Initialize translator\ntranslator = Gemma3nTranslator(MODEL_PATH)\n\n# Supported languages\nSUPPORTED_LANGUAGES = {\n    \"Arabic\": \"Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©\",\n    \"Chinese\": \"ä¸­æ–‡\",\n    \"Spanish\": \"EspaÃ±ol\",\n    \"French\": \"FranÃ§ais\",\n    \"German\": \"Deutsch\",\n    \"Italian\": \"Italiano\",\n    \"Portuguese\": \"PortuguÃªs\",\n    \"Russian\": \"Ğ ÑƒÑÑĞºĞ¸Ğ¹\",\n    \"Japanese\": \"æ—¥æœ¬èª\",\n    \"Korean\": \"í•œêµ­ì–´\",\n    \"Hindi\": \"à¤¹à¤¿à¤¨à¥à¤¦à¥€\",\n    \"Turkish\": \"TÃ¼rkÃ§e\",\n    \"Dutch\": \"Nederlands\",\n    \"Swedish\": \"Svenska\",\n    \"Norwegian\": \"Norsk\",\n    \"Polish\": \"Polski\",\n    \"Czech\": \"ÄŒeÅ¡tina\",\n    \"Greek\": \"Î•Î»Î»Î·Î½Î¹ÎºÎ¬\",\n    \"Hebrew\": \"×¢×‘×¨×™×ª\",\n    \"Thai\": \"à¹„à¸—à¸¢\"\n}\n\nprint(\"ğŸŒ Supported Languages:\")\nfor lang, native in SUPPORTED_LANGUAGES.items():\n    print(f\"â€¢ {lang} ({native})\")\n\n# Expanded phrasebook\ntranslator.phrasebook = {\n    \"Arabic\": {\n        \"Hello\": \"Ù…Ø±Ø­Ø¨Ø§\",\n        \"Good morning\": \"ØµØ¨Ø§Ø­ Ø§Ù„Ø®ÙŠØ±\",\n        \"Good evening\": \"Ù…Ø³Ø§Ø¡ Ø§Ù„Ø®ÙŠØ±\",\n        \"Where is the bathroom?\": \"Ø£ÙŠÙ† Ø§Ù„Ø­Ù…Ø§Ù…ØŸ\",\n        \"I need help\": \"Ø£Ø­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ù…Ø³Ø§Ø¹Ø¯Ø©\",\n        \"How much does this scooter cost for 1 day?\": \"ÙƒÙ… ØªÙƒÙ„ÙØ© Ù‡Ø°Ø§ Ø§Ù„Ø¯Ø±Ø§Ø¬Ø© Ø§Ù„Ù†Ø§Ø±ÙŠØ© Ù„Ù…Ø¯Ø© ÙŠÙˆÙ… ÙˆØ§Ø­Ø¯ØŸ\",\n        \"Where is the bus station?\": \"Ø£ÙŠÙ† Ù…Ø­Ø·Ø© Ø§Ù„Ø­Ø§ÙÙ„Ø§ØªØŸ\",\n        \"I would like to order\": \"Ø£ÙˆØ¯ Ø£Ù† Ø£Ø·Ù„Ø¨\",\n        \"Can I see the menu?\": \"Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ø±Ø¤ÙŠØ© Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©ØŸ\",\n        \"I need a doctor\": \"Ø£Ø­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ø·Ø¨ÙŠØ¨\",\n        \"Call the police\": \"Ø§ØªØµÙ„ Ø¨Ø§Ù„Ø´Ø±Ø·Ø©\",\n        \"Where is the nearest restaurant?\": \"Ø£ÙŠÙ† Ø£Ù‚Ø±Ø¨ Ù…Ø·Ø¹Ù…ØŸ\",\n        \"Can you help me find a hotel?\": \"Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ùƒ Ù…Ø³Ø§Ø¹Ø¯ØªÙŠ ÙÙŠ Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ÙÙ†Ø¯Ù‚ØŸ\",\n        \"What time does the store close?\": \"ÙÙŠ Ø£ÙŠ ÙˆÙ‚Øª ÙŠØºÙ„Ù‚ Ø§Ù„Ù…ØªØ¬Ø±ØŸ\",\n        \"I would like to order coffee, please.\": \"Ø£ÙˆØ¯ Ø·Ù„Ø¨ Ù‚Ù‡ÙˆØ©ØŒ Ù…Ù† ÙØ¶Ù„Ùƒ.\",\n        \"How do I get to the airport?\": \"ÙƒÙŠÙ Ø£ØµÙ„ Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø·Ø§Ø±ØŸ\",\n        \"Is there a pharmacy nearby?\": \"Ù‡Ù„ ÙŠÙˆØ¬Ø¯ ØµÙŠØ¯Ù„ÙŠØ© Ù‚Ø±ÙŠØ¨Ø©ØŸ\",\n        \"What is the weather like today?\": \"ÙƒÙŠÙ Ù‡Ùˆ Ø§Ù„Ø·Ù‚Ø³ Ø§Ù„ÙŠÙˆÙ…ØŸ\",\n        \"Where can I find good local food?\": \"Ø£ÙŠÙ† ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø·Ø¹Ø§Ù… Ù…Ø­Ù„ÙŠ Ø¬ÙŠØ¯ØŸ\",\n        \"Is there wifi in the hotel?\": \"Ù‡Ù„ ÙŠÙˆØ¬Ø¯ ÙˆØ§ÙŠ ÙØ§ÙŠ ÙÙŠ Ø§Ù„ÙÙ†Ø¯Ù‚ØŸ\",\n        \"How do I get to the train station?\": \"ÙƒÙŠÙ Ø£ØµÙ„ Ø¥Ù„Ù‰ Ù…Ø­Ø·Ø© Ø§Ù„Ù‚Ø·Ø§Ø±ØŸ\",\n        \"Can you recommend a good restaurant nearby?\": \"Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„ØªÙˆØµÙŠØ© Ø¨Ù…Ø·Ø¹Ù… Ø¬ÙŠØ¯ Ù‚Ø±ÙŠØ¨ØŸ\",\n        \"What time is the meeting?\": \"Ù…Ø§ Ù‡Ùˆ Ù…ÙˆØ¹Ø¯ Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ØŸ\",\n        \"Can you send me the report?\": \"Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ùƒ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ù„ÙŠØŸ\",\n        \"Let's schedule a call for tomorrow\": \"Ø¯Ø¹Ù†Ø§ Ù†Ø­Ø¯Ø¯ Ù…ÙˆØ¹Ø¯ Ù…ÙƒØ§Ù„Ù…Ø© ØºØ¯Ù‹Ø§\",\n        \"The project deadline is next week\": \"Ø§Ù„Ù…ÙˆØ¹Ø¯ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ù„Ù„Ù…Ø´Ø±ÙˆØ¹ Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ Ø§Ù„Ù…Ù‚Ø¨Ù„\",\n        \"Thank you for your presentation\": \"Ø´ÙƒØ±Ø§ Ù„Ø¹Ø±Ø¶Ùƒ Ø§Ù„ØªÙ‚Ø¯ÙŠÙ…ÙŠ\"\n    },\n    \"Chinese\": {\n        \"Hello\": \"ä½ å¥½\",\n        \"Good morning\": \"æ—©ä¸Šå¥½\",\n        \"Good evening\": \"æ™šä¸Šå¥½\",\n        \"Where is the bathroom?\": \"æ´—æ‰‹é—´åœ¨å“ªé‡Œï¼Ÿ\",\n        \"I need help\": \"æˆ‘éœ€è¦å¸®åŠ©\",\n        \"How much does this scooter cost for 1 day?\": \"è¿™è¾†è¸æ¿è½¦ä¸€å¤©å¤šå°‘é’±ï¼Ÿ\",\n        \"Where is the bus station?\": \"å…¬äº¤è½¦ç«™åœ¨å“ªé‡Œï¼Ÿ\",\n        \"I would like to order\": \"æˆ‘æƒ³ç‚¹èœ\",\n        \"Can I see the menu?\": \"æˆ‘å¯ä»¥çœ‹èœå•å—ï¼Ÿ\",\n        \"I need a doctor\": \"æˆ‘éœ€è¦åŒ»ç”Ÿ\",\n        \"Call the police\": \"æŠ¥è­¦\",\n        \"Where is the nearest restaurant?\": \"æœ€è¿‘çš„é¤å…åœ¨å“ªé‡Œï¼Ÿ\",\n        \"Can you help me find a hotel?\": \"ä½ èƒ½å¸®æˆ‘æ‰¾ä¸€å®¶é…’åº—å—ï¼Ÿ\",\n        \"What time does the store close?\": \"å•†åº—ä»€ä¹ˆæ—¶å€™å…³é—¨ï¼Ÿ\",\n        \"I would like to order coffee, please.\": \"æˆ‘æƒ³ç‚¹æ¯å’–å•¡ï¼Œè°¢è°¢ã€‚\",\n        \"How do I get to the airport?\": \"æ€ä¹ˆå»æœºåœºï¼Ÿ\",\n        \"Is there a pharmacy nearby?\": \"é™„è¿‘æœ‰è¯åº—å—ï¼Ÿ\",\n        \"What is the weather like today?\": \"ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\",\n        \"Where can I find good local food?\": \"å“ªé‡Œå¯ä»¥æ‰¾åˆ°å¥½çš„å½“åœ°ç¾é£Ÿï¼Ÿ\",\n        \"Is there wifi in the hotel?\": \"é…’åº—æœ‰æ— çº¿ç½‘ç»œå—ï¼Ÿ\",\n        \"How do I get to the train station?\": \"æ€ä¹ˆå»ç«è½¦ç«™ï¼Ÿ\",\n        \"Can you recommend a good restaurant nearby?\": \"ä½ èƒ½æ¨èä¸€å®¶é™„è¿‘çš„é¤å…å—ï¼Ÿ\",\n        \"What time is the meeting?\": \"ä¼šè®®æ˜¯ä»€ä¹ˆæ—¶é—´ï¼Ÿ\",\n        \"Can you send me the report?\": \"ä½ èƒ½æŠŠæŠ¥å‘Šå‘ç»™æˆ‘å—ï¼Ÿ\",\n        \"Let's schedule a call for tomorrow\": \"æˆ‘ä»¬å®‰æ’æ˜å¤©é€šè¯å§\",\n        \"The project deadline is next week\": \"é¡¹ç›®æˆªæ­¢æ—¥æœŸæ˜¯ä¸‹å‘¨\",\n        \"Thank you for your presentation\": \"æ„Ÿè°¢ä½ çš„æ¼”è®²\"\n    },\n    \"Spanish\": {\n        \"Hello\": \"Hola\",\n        \"Good morning\": \"Buenos dÃ­as\",\n        \"Good evening\": \"Buenas noches\",\n        \"Where is the bathroom?\": \"Â¿DÃ³nde estÃ¡ el baÃ±o?\",\n        \"I need help\": \"Necesito ayuda\",\n        \"How much does this scooter cost for 1 day?\": \"Â¿CuÃ¡nto cuesta este scooter por un dÃ­a?\",\n        \"Where is the bus station?\": \"Â¿DÃ³nde estÃ¡ la estaciÃ³n de autobuses?\",\n        \"I would like to order\": \"Quiero pedir\",\n        \"Can I see the menu?\": \"Â¿Puedo ver el menÃº?\",\n        \"I need a doctor\": \"Necesito un mÃ©dico\",\n        \"Call the police\": \"Llama a la policÃ­a\",\n        \"Where is the nearest restaurant?\": \"Â¿DÃ³nde estÃ¡ el restaurante mÃ¡s cercano?\",\n        \"Can you help me find a hotel?\": \"Â¿Puedes ayudarme a encontrar un hotel?\",\n        \"What time does the store close?\": \"Â¿A quÃ© hora cierra la tienda?\",\n        \"I would like to order coffee, please.\": \"Quiero pedir un cafÃ©, por favor.\",\n        \"How do I get to the airport?\": \"Â¿CÃ³mo llego al aeropuerto?\",\n        \"Is there a pharmacy nearby?\": \"Â¿Hay una farmacia cerca?\",\n        \"What is the weather like today?\": \"Â¿CÃ³mo estÃ¡ el clima hoy?\",\n        \"Where can I find good local food?\": \"Â¿DÃ³nde puedo encontrar comida local buena?\",\n        \"Is there wifi in the hotel?\": \"Â¿Hay wifi en el hotel?\",\n        \"How do I get to the train station?\": \"Â¿CÃ³mo llego a la estaciÃ³n de tren?\",\n        \"Can you recommend a good restaurant nearby?\": \"Â¿Puedes recomendar un buen restaurante cerca?\",\n        \"What time is the meeting?\": \"Â¿A quÃ© hora es la reuniÃ³n?\",\n        \"Can you send me the report?\": \"Â¿Puedes enviarme el informe?\",\n        \"Let's schedule a call for tomorrow\": \"Programemos una llamada para maÃ±ana\",\n        \"The project deadline is next week\": \"La fecha lÃ­mite del proyecto es la prÃ³xima semana\",\n        \"Thank you for your presentation\": \"Gracias por tu presentaciÃ³n\"\n    },\n    \"French\": {\n        \"Hello\": \"Bonjour\",\n        \"Good morning\": \"Bonjour\",\n        \"Good evening\": \"Bonsoir\",\n        \"Where is the bathroom?\": \"OÃ¹ sont les toilettes ?\",\n        \"I need help\": \"J'ai besoin d'aide\",\n        \"How much does this scooter cost for 1 day?\": \"Combien coÃ»te ce scooter pour une journÃ©e ?\",\n        \"Where is the bus station?\": \"OÃ¹ est la gare routiÃ¨re ?\",\n        \"I would like to order\": \"Je voudrais commander\",\n        \"Can I see the menu?\": \"Puis-je voir le menu ?\",\n        \"I need a doctor\": \"J'ai besoin d'un mÃ©decin\",\n        \"Call the police\": \"Appelez la police\",\n        \"Where is the nearest restaurant?\": \"OÃ¹ se trouve le restaurant le plus proche ?\",\n        \"Can you help me find a hotel?\": \"Pouvez-vous m'aider Ã  trouver un hÃ´tel ?\",\n        \"What time does the store close?\": \"Ã€ quelle heure le magasin ferme-t-il ?\",\n        \"I would like to order coffee, please.\": \"Je voudrais commander un cafÃ©, s'il vous plaÃ®t.\",\n        \"How do I get to the airport?\": \"Comment puis-je me rendre Ã  l'aÃ©roport ?\",\n        \"Is there a pharmacy nearby?\": \"Y a-t-il une pharmacie Ã  proximitÃ© ?\",\n        \"What is the weather like today?\": \"Quel temps fait-il aujourd'hui ?\",\n        \"Where can I find good local food?\": \"OÃ¹ puis-je trouver de la bonne nourriture locale ?\",\n        \"Is there wifi in the hotel?\": \"Y a-t-il du wifi dans l'hÃ´tel ?\",\n        \"How do I get to the train station?\": \"Comment puis-je me rendre Ã  la gare ?\",\n        \"Can you recommend a good restaurant nearby?\": \"Pouvez-vous recommander un bon restaurant Ã  proximitÃ© ?\",\n        \"What time is the meeting?\": \"Ã€ quelle heure est la rÃ©union ?\",\n        \"Can you send me the report?\": \"Pouvez-vous m'envoyer le rapport ?\",\n        \"Let's schedule a call for tomorrow\": \"Programmons un appel pour demain\",\n        \"The project deadline is next week\": \"La date limite du projet est la semaine prochaine\",\n        \"Thank you for your presentation\": \"Merci pour votre prÃ©sentation\"\n    }\n}\n\nprint(\"ğŸ”„ Starting Translation Examples...\")\nprint(\"=\" * 60)\n\n# Translate to Arabic\nprint(\"\\nğŸ‡¸ğŸ‡¦ ENGLISH â†’ ARABIC\")\nprint(\"-\" * 30)\nfor sentence in [\"How much does this scooter cost for 1 day?\", \"Where is the nearest restaurant?\",\n                 \"Can you help me find a hotel?\", \"What time does the store close?\"]:\n    translation = translator.translate(sentence, \"Arabic\")\n    print(f\"ğŸ‡ºğŸ‡¸ EN: {sentence}\")\n    print(f\"ğŸ‡¸ğŸ‡¦ AR: {translation}\")\n    print()\n\n# Translate to Chinese\nprint(\"\\nğŸ‡¨ğŸ‡³ ENGLISH â†’ CHINESE\")\nprint(\"-\" * 30)\nfor sentence in [\"I would like to order coffee, please.\", \"How do I get to the airport?\",\n                 \"Is there a pharmacy nearby?\", \"What is the weather like today?\"]:\n    translation = translator.translate(sentence, \"Chinese\")\n    print(f\"ğŸ‡ºğŸ‡¸ EN: {sentence}\")\n    print(f\"ğŸ‡¨ğŸ‡³ ZH: {translation}\")\n    print()\n\n# Interactive translator\ndef interactive_translator():\n    print(\"ğŸŒ Gemma 3N Interactive Translator\")\n    print(\"=\" * 40)\n    print(\"Available languages:\", \", \".join(SUPPORTED_LANGUAGES.keys()))\n    print(\"Type 'quit' to exit\\n\")\n\n    while True:\n        text = input(\"ğŸ“ Enter text to translate (English): \")\n        if text.lower() == 'quit':\n            break\n        target_lang = input(\"ğŸ¯ Target language: \")\n        if target_lang not in SUPPORTED_LANGUAGES:\n            print(f\"âŒ Language '{target_lang}' not supported. Using Arabic.\")\n            target_lang = \"Arabic\"\n        translation = translator.translate(text, target_lang)\n        print(f\"âœ… Translation: {translation}\")\n        print(\"-\" * 50)\n\n# Uncomment to run interactive mode\n# interactive_translator()\n\n# Performance analysis\ndef analyze_performance():\n    test_text = \"How much does this scooter cost for 1 day?\"\n    results = []\n\n    print(\"ğŸ“Š Performance Analysis\")\n    print(\"=\" * 40)\n\n    for language in [\"Arabic\", \"Chinese\", \"Spanish\", \"French\"]:\n        start_time = time.time()\n        translation = translator.translate(test_text, language)\n        end_time = time.time()\n\n        results.append({\n            'Language': language,\n            'Translation': translation,\n            'Time (seconds)': round(end_time - start_time, 2),\n            'Characters': len(translation)\n        })\n\n    df = pd.DataFrame(results)\n    print(df.to_string(index=False))\n\n    print(f\"\\nğŸ“Š Average translation time: {df['Time (seconds)'].mean():.2f} seconds\")\n    print(f\"ğŸ“Š Fastest translation: {df.loc[df['Time (seconds)'].idxmin(), 'Language']} ({df['Time (seconds)'].min():.2f}s)\")\n    print(f\"ğŸ“Š Slowest translation: {df.loc[df['Time (seconds)'].idxmax(), 'Language']} ({df['Time (seconds)'].max():.2f}s)\")\n\n    return df\n\nperformance_df = analyze_performance()\n\n# Advanced translator\nclass AdvancedTranslator(Gemma3nTranslator):\n    def __init__(self, model_path: str):\n        super().__init__(model_path)\n        self.phrasebook = translator.phrasebook\n\n    def translate_with_context(self, text: str, target_language: str, context: str = \"\") -> str:\n        if context:\n            text = f\"{context}: {text}\"\n        return self.translate(text, target_language)\n\n    def detect_language(self, text: str) -> str:\n        return \"English\"  # Placeholder\n\n    def translate_conversation(self, conversation: List[str], target_language: str) -> List[str]:\n        return self.batch_translate(conversation, target_language)\n\n# Initialize advanced translator\nadvanced_translator = AdvancedTranslator(MODEL_PATH)\n\n# Travel and business translations\ntravel_phrases = [\n    \"How much does this scooter cost for 1 day?\",\n    \"Where can I find good local food?\",\n    \"Is there wifi in the hotel?\",\n    \"How do I get to the train station?\",\n    \"Can you recommend a good restaurant nearby?\"\n]\n\nbusiness_phrases = [\n    \"What time is the meeting?\",\n    \"Can you send me the report?\",\n    \"Let's schedule a call for tomorrow\",\n    \"The project deadline is next week\",\n    \"Thank you for your presentation\"\n]\n\nprint(\"âœˆï¸ TRAVEL TRANSLATION EXAMPLES\")\nprint(\"=\" * 50)\nprint(\"\\nğŸ‡¸ğŸ‡¦ Travel Phrases in Arabic:\")\nfor phrase in travel_phrases:\n    translation = advanced_translator.translate_with_context(phrase, \"Arabic\", \"travel\")\n    print(f\"ğŸ‡ºğŸ‡¸ {phrase}\")\n    print(f\"ğŸ‡¸ğŸ‡¦ {translation}\\n\")\n\nprint(\"\\nğŸ’¼ BUSINESS TRANSLATION EXAMPLES\")\nprint(\"=\" * 50)\nprint(\"\\nğŸ‡¨ğŸ‡³ Business Phrases in Chinese:\")\nfor phrase in business_phrases:\n    translation = advanced_translator.translate_with_context(phrase, \"Chinese\", \"business\")\n    print(f\"ğŸ‡ºğŸ‡¸ {phrase}\")\n    print(f\"ğŸ‡¨ğŸ‡³ {translation}\\n\")\n\n# Model info\ndef display_model_info():\n    print(\"ğŸ¤– GEMMA 3N MODEL INFORMATION\")\n    print(\"=\" * 50)\n    print(\"ğŸ“Š Model Architecture: Gemma 3n-E2B-IT (Instruction Tuned)\")\n    print(\"ğŸ“Š Quantization: INT4 (4-bit quantization)\")\n    print(\"ğŸ“Š Framework: TensorFlow Lite\")\n    print(f\"ğŸ“Š Inference Device: {'GPU' if translator.gpu_enabled else 'CPU'}\")\n    print(\"ğŸ“Š Languages Supported: 140+ (embedding-based)\")\n    print(\"ğŸ“Š Optimization: Edge/Mobile devices\")\n    print(\"ğŸ“Š Memory Footprint: ~4B active parameters\")\n    print(f\"ğŸ“Š Model File Size: {os.path.getsize(MODEL_PATH) / (1024*1024):.1f} MB\")\n    print(\"\\nğŸš€ KEY FEATURES:\")\n    print(\"â€¢ Runs offline\")\n    print(\"â€¢ Optimized for low-resource devices\")\n    print(\"â€¢ Privacy-focused\")\n\ndisplay_model_info()\n\n# Export phrasebook\ndef export_phrasebook_to_csv(filename=\"phrasebook.csv\"):\n    data = []\n    for lang, phrases in translator.phrasebook.items():\n        for eng, trans in phrases.items():\n            data.append({\"English\": eng, \"Language\": lang, \"Translation\": trans})\n    df = pd.DataFrame(data)\n    df.to_csv(filename, index=False)\n    print(f\"âœ… Phrasebook exported to {filename}\")\n    return df\n\nexport_phrasebook_to_csv()\n\n# Phrasebook creation\ndef create_translation_phrasebook():\n    common_phrases = {\n        \"Greetings\": [\"Hello\", \"Good morning\", \"Good evening\"],\n        \"Basic Needs\": [\"Where is the bathroom?\", \"I need help\"],\n        \"Transportation\": [\"How much does this scooter cost for 1 day?\", \"Where is the bus station?\"],\n        \"Food & Dining\": [\"I would like to order\", \"Can I see the menu?\"],\n        \"Emergency\": [\"I need a doctor\", \"Call the police\"]\n    }\n\n    target_languages = [\"Arabic\", \"Chinese\", \"Spanish\", \"French\"]\n    for lang in target_languages:\n        if lang not in translator.phrasebook:\n            translator.phrasebook[lang] = {}\n        print(f\"\\nğŸŒ Creating {lang} phrasebook...\")\n        for category, phrases in common_phrases.items():\n            print(f\"ğŸ“ Translating {category}...\")\n            for phrase in phrases:\n                if phrase not in translator.phrasebook[lang]:\n                    translation = translator.translate(phrase, lang)\n                    translator.phrasebook[lang][phrase] = translation\n\n    return translator.phrasebook\n\nprint(\"ğŸ“š Creating Multilingual Phrasebook...\")\nphrasebook = create_translation_phrasebook()\n\n# Translation accuracy test\ndef test_translation_accuracy():\n    test_cases = [\n        {\n            \"english\": \"Hello, how are you?\",\n            \"arabic_expected\": \"Ù…Ø±Ø­Ø¨Ø§ØŒ ÙƒÙŠÙ Ø­Ø§Ù„ÙƒØŸ\",\n            \"chinese_expected\": \"ä½ å¥½ï¼Œä½ å¥½å—ï¼Ÿ\"\n        },\n        {\n            \"english\": \"Thank you very much\",\n            \"arabic_expected\": \"Ø´ÙƒØ±Ø§ Ø¬Ø²ÙŠÙ„Ø§\",\n            \"chinese_expected\": \"éå¸¸æ„Ÿè°¢\"\n        },\n        {\n            \"english\": \"How much does this scooter cost for 1 day?\",\n            \"arabic_expected\": \"ÙƒÙ… ØªÙƒÙ„ÙØ© Ù‡Ø°Ø§ Ø§Ù„Ø¯Ø±Ø§Ø¬Ø© Ø§Ù„Ù†Ø§Ø±ÙŠØ© Ù„Ù…Ø¯Ø© ÙŠÙˆÙ… ÙˆØ§Ø­Ø¯ØŸ\",\n            \"chinese_expected\": \"è¿™è¾†è¸æ¿è½¦ä¸€å¤©å¤šå°‘é’±ï¼Ÿ\"\n        }\n    ]\n\n    print(\"ğŸ§ª TRANSLATION ACCURACY TESTING\")\n    print(\"=\" * 50)\n\n    for i, test_case in enumerate(test_cases, 1):\n        print(f\"\\nğŸ“ Test Case {i}:\")\n        print(f\"English: {test_case['english']}\")\n        arabic_result = translator.translate(test_case['english'], \"Arabic\")\n        chinese_result = translator.translate(test_case['english'], \"Chinese\")\n        print(f\"Arabic Result: {arabic_result}\")\n        print(f\"Arabic Expected: {test_case['arabic_expected']}\")\n        print(f\"Chinese Result: {chinese_result}\")\n        print(f\"Chinese Expected: {test_case['chinese_expected']}\")\n        print(\"-\" * 30)\n\ntest_translation_accuracy()\n\n# Troubleshooting guide\ndef troubleshoot_common_issues():\n    print(\"ğŸ”§ TROUBLESHOOTING GUIDE\")\n    print(\"=\" * 40)\n    print(\"âŒ Issue: Model not found\")\n    print(\"âœ… Solution: Ensure Gemma 3N dataset is added to notebook inputs\")\n    print(\"\\nâŒ Issue: Translation fails\")\n    print(\"âœ… Solution: Verify TF_LITE_EMBEDDER and TOKENIZER_MODEL are extracted; check phrasebook\")\n    print(\"\\nâŒ Issue: Out of memory\")\n    print(\"âœ… Solution: Restart kernel and limit input text length\")\n    print(\"\\nâŒ Issue: Language not supported\")\n    print(\"âœ… Solution: Add translations to phrasebook for the target language\")\n    print(\"\\nâŒ Issue: GPU delegate not working\")\n    print(\"âœ… Solution: Ensure TensorFlow is up-to-date; verify GPU availability with nvidia-smi\")\n    print(\"\\nâŒ Issue: EMBEDDING_LOOKUP op not supported\")\n    print(\"âœ… Solution: Update TensorFlow to 2.16.0 or higher; ensure model compatibility\")\n\ntroubleshoot_common_issues()\n\n# Verify environment and GPU usage\nprint(\"\\nğŸ” Verifying Environment\")\nprint(f\"TensorFlow version: {tf.__version__}\")\nprint(f\"TensorFlow GPU available: {tf.test.is_gpu_available()}\")\nprint(\"\\nğŸ” Verifying GPU Usage\")\n!nvidia-smi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-28T02:22:56.940298Z","iopub.execute_input":"2025-06-28T02:22:56.940913Z","iopub.status.idle":"2025-06-28T02:23:31.847543Z","shell.execute_reply.started":"2025-06-28T02:22:56.940887Z","shell.execute_reply":"2025-06-28T02:23:31.846694Z"}},"outputs":[{"name":"stdout","text":"âœ… TensorFlow GPU enabled\nâœ… Model found at: /kaggle/input/gemma-3n/tflite/gemma-3n-e2b-it-int4/1/gemma-3n-E2B-it-int4.task\nğŸ“Š Model size: 2990.9 MB\nâœ… Tokenizer loaded: 262144 tokens\nâš ï¸ GPU delegate not available, using CPU\nâœ… Embedder loaded\nğŸŒ Supported Languages:\nâ€¢ Arabic (Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©)\nâ€¢ Chinese (ä¸­æ–‡)\nâ€¢ Spanish (EspaÃ±ol)\nâ€¢ French (FranÃ§ais)\nâ€¢ German (Deutsch)\nâ€¢ Italian (Italiano)\nâ€¢ Portuguese (PortuguÃªs)\nâ€¢ Russian (Ğ ÑƒÑÑĞºĞ¸Ğ¹)\nâ€¢ Japanese (æ—¥æœ¬èª)\nâ€¢ Korean (í•œêµ­ì–´)\nâ€¢ Hindi (à¤¹à¤¿à¤¨à¥à¤¦à¥€)\nâ€¢ Turkish (TÃ¼rkÃ§e)\nâ€¢ Dutch (Nederlands)\nâ€¢ Swedish (Svenska)\nâ€¢ Norwegian (Norsk)\nâ€¢ Polish (Polski)\nâ€¢ Czech (ÄŒeÅ¡tina)\nâ€¢ Greek (Î•Î»Î»Î·Î½Î¹ÎºÎ¬)\nâ€¢ Hebrew (×¢×‘×¨×™×ª)\nâ€¢ Thai (à¹„à¸—à¸¢)\nğŸ”„ Starting Translation Examples...\n============================================================\n\nğŸ‡¸ğŸ‡¦ ENGLISH â†’ ARABIC\n------------------------------\nâ±ï¸ Translation completed in 0.01 seconds (GPU: False)\nğŸ‡ºğŸ‡¸ EN: How much does this scooter cost for 1 day?\nğŸ‡¸ğŸ‡¦ AR: ÙƒÙ… ØªÙƒÙ„ÙØ© Ù‡Ø°Ø§ Ø§Ù„Ø¯Ø±Ø§Ø¬Ø© Ø§Ù„Ù†Ø§Ø±ÙŠØ© Ù„Ù…Ø¯Ø© ÙŠÙˆÙ… ÙˆØ§Ø­Ø¯ØŸ\n\nâ±ï¸ Translation completed in 0.01 seconds (GPU: False)\nğŸ‡ºğŸ‡¸ EN: Where is the nearest restaurant?\nğŸ‡¸ğŸ‡¦ AR: Ø£ÙŠÙ† Ø£Ù‚Ø±Ø¨ Ù…Ø·Ø¹Ù…ØŸ\n\nâ±ï¸ Translation completed in 0.01 seconds (GPU: False)\nğŸ‡ºğŸ‡¸ EN: Can you help me find a hotel?\nğŸ‡¸ğŸ‡¦ AR: Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ùƒ Ù…Ø³Ø§Ø¹Ø¯ØªÙŠ ÙÙŠ Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ÙÙ†Ø¯Ù‚ØŸ\n\nâ±ï¸ Translation completed in 0.01 seconds (GPU: False)\nğŸ‡ºğŸ‡¸ EN: What time does the store close?\nğŸ‡¸ğŸ‡¦ AR: ÙÙŠ Ø£ÙŠ ÙˆÙ‚Øª ÙŠØºÙ„Ù‚ Ø§Ù„Ù…ØªØ¬Ø±ØŸ\n\n\nğŸ‡¨ğŸ‡³ ENGLISH â†’ CHINESE\n------------------------------\nâ±ï¸ Translation completed in 0.01 seconds (GPU: False)\nğŸ‡ºğŸ‡¸ EN: I would like to order coffee, please.\nğŸ‡¨ğŸ‡³ ZH: æˆ‘æƒ³ç‚¹æ¯å’–å•¡ï¼Œè°¢è°¢ã€‚\n\nâ±ï¸ Translation completed in 0.01 seconds (GPU: False)\nğŸ‡ºğŸ‡¸ EN: How do I get to the airport?\nğŸ‡¨ğŸ‡³ ZH: æ€ä¹ˆå»æœºåœºï¼Ÿ\n\nâ±ï¸ Translation completed in 0.01 seconds (GPU: False)\nğŸ‡ºğŸ‡¸ EN: Is there a pharmacy nearby?\nğŸ‡¨ğŸ‡³ ZH: é™„è¿‘æœ‰è¯åº—å—ï¼Ÿ\n\nâ±ï¸ Translation completed in 0.01 seconds (GPU: False)\nğŸ‡ºğŸ‡¸ EN: What is the weather like today?\nğŸ‡¨ğŸ‡³ ZH: ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\n\nğŸ“Š Performance Analysis\n========================================\nâ±ï¸ Translation completed in 0.01 seconds (GPU: False)\nâ±ï¸ Translation completed in 0.01 seconds (GPU: False)\nâ±ï¸ Translation completed in 0.01 seconds (GPU: False)\nâ±ï¸ Translation completed in 0.01 seconds (GPU: False)\nLanguage                                 Translation  Time (seconds)  Characters\n  Arabic ÙƒÙ… ØªÙƒÙ„ÙØ© Ù‡Ø°Ø§ Ø§Ù„Ø¯Ø±Ø§Ø¬Ø© Ø§Ù„Ù†Ø§Ø±ÙŠØ© Ù„Ù…Ø¯Ø© ÙŠÙˆÙ… ÙˆØ§Ø­Ø¯ØŸ            0.01          43\n Chinese                                 è¿™è¾†è¸æ¿è½¦ä¸€å¤©å¤šå°‘é’±ï¼Ÿ            0.01          11\n Spanish     Â¿CuÃ¡nto cuesta este scooter por un dÃ­a?            0.01          39\n  French Combien coÃ»te ce scooter pour une journÃ©e ?            0.01          43\n\nğŸ“Š Average translation time: 0.01 seconds\nğŸ“Š Fastest translation: Arabic (0.01s)\nğŸ“Š Slowest translation: Arabic (0.01s)\nâœ… Tokenizer loaded: 262144 tokens\nâš ï¸ GPU delegate not available, using CPU\nâœ… Embedder loaded\nâœˆï¸ TRAVEL TRANSLATION EXAMPLES\n==================================================\n\nğŸ‡¸ğŸ‡¦ Travel Phrases in Arabic:\nâ±ï¸ Translation completed in 0.01 seconds (GPU: False)\nğŸ‡ºğŸ‡¸ How much does this scooter cost for 1 day?\nğŸ‡¸ğŸ‡¦ ÙƒÙ… ØªÙƒÙ„ÙØ© Ù‡Ø°Ø§ Ø§Ù„Ø¯Ø±Ø§Ø¬Ø© Ø§Ù„Ù†Ø§Ø±ÙŠØ© Ù„Ù…Ø¯Ø© ÙŠÙˆÙ… ÙˆØ§Ø­Ø¯ØŸ\n\nâ±ï¸ Translation completed in 0.01 seconds (GPU: False)\nğŸ‡ºğŸ‡¸ Where can I find good local food?\nğŸ‡¸ğŸ‡¦ Ø£ÙŠÙ† ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø·Ø¹Ø§Ù… Ù…Ø­Ù„ÙŠ Ø¬ÙŠØ¯ØŸ\n\nâ±ï¸ Translation completed in 0.01 seconds (GPU: False)\nğŸ‡ºğŸ‡¸ Is there wifi in the hotel?\nğŸ‡¸ğŸ‡¦ Ù‡Ù„ ÙŠÙˆØ¬Ø¯ ÙˆØ§ÙŠ ÙØ§ÙŠ ÙÙŠ Ø§Ù„ÙÙ†Ø¯Ù‚ØŸ\n\nâ±ï¸ Translation completed in 0.01 seconds (GPU: False)\nğŸ‡ºğŸ‡¸ How do I get to the train station?\nğŸ‡¸ğŸ‡¦ ÙƒÙŠÙ Ø£ØµÙ„ Ø¥Ù„Ù‰ Ù…Ø­Ø·Ø© Ø§Ù„Ù‚Ø·Ø§Ø±ØŸ\n\nâ±ï¸ Translation completed in 0.01 seconds (GPU: False)\nğŸ‡ºğŸ‡¸ Can you recommend a good restaurant nearby?\nğŸ‡¸ğŸ‡¦ Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„ØªÙˆØµÙŠØ© Ø¨Ù…Ø·Ø¹Ù… Ø¬ÙŠØ¯ Ù‚Ø±ÙŠØ¨ØŸ\n\n\nğŸ’¼ BUSINESS TRANSLATION EXAMPLES\n==================================================\n\nğŸ‡¨ğŸ‡³ Business Phrases in Chinese:\nâ±ï¸ Translation completed in 0.01 seconds (GPU: False)\nğŸ‡ºğŸ‡¸ What time is the meeting?\nğŸ‡¨ğŸ‡³ ä¼šè®®æ˜¯ä»€ä¹ˆæ—¶é—´ï¼Ÿ\n\nâ±ï¸ Translation completed in 0.01 seconds (GPU: False)\nğŸ‡ºğŸ‡¸ Can you send me the report?\nğŸ‡¨ğŸ‡³ ä½ èƒ½æŠŠæŠ¥å‘Šå‘ç»™æˆ‘å—ï¼Ÿ\n\nâ±ï¸ Translation completed in 0.01 seconds (GPU: False)\nğŸ‡ºğŸ‡¸ Let's schedule a call for tomorrow\nğŸ‡¨ğŸ‡³ æˆ‘ä»¬å®‰æ’æ˜å¤©é€šè¯å§\n\nâ±ï¸ Translation completed in 0.01 seconds (GPU: False)\nğŸ‡ºğŸ‡¸ The project deadline is next week\nğŸ‡¨ğŸ‡³ é¡¹ç›®æˆªæ­¢æ—¥æœŸæ˜¯ä¸‹å‘¨\n\nâ±ï¸ Translation completed in 0.01 seconds (GPU: False)\nğŸ‡ºğŸ‡¸ Thank you for your presentation\nğŸ‡¨ğŸ‡³ æ„Ÿè°¢ä½ çš„æ¼”è®²\n\nğŸ¤– GEMMA 3N MODEL INFORMATION\n==================================================\nğŸ“Š Model Architecture: Gemma 3n-E2B-IT (Instruction Tuned)\nğŸ“Š Quantization: INT4 (4-bit quantization)\nğŸ“Š Framework: TensorFlow Lite\nğŸ“Š Inference Device: CPU\nğŸ“Š Languages Supported: 140+ (embedding-based)\nğŸ“Š Optimization: Edge/Mobile devices\nğŸ“Š Memory Footprint: ~4B active parameters\nğŸ“Š Model File Size: 2990.9 MB\n\nğŸš€ KEY FEATURES:\nâ€¢ Runs offline\nâ€¢ Optimized for low-resource devices\nâ€¢ Privacy-focused\nâœ… Phrasebook exported to phrasebook.csv\nğŸ“š Creating Multilingual Phrasebook...\n\nğŸŒ Creating Arabic phrasebook...\nğŸ“ Translating Greetings...\nğŸ“ Translating Basic Needs...\nğŸ“ Translating Transportation...\nğŸ“ Translating Food & Dining...\nğŸ“ Translating Emergency...\n\nğŸŒ Creating Chinese phrasebook...\nğŸ“ Translating Greetings...\nğŸ“ Translating Basic Needs...\nğŸ“ Translating Transportation...\nğŸ“ Translating Food & Dining...\nğŸ“ Translating Emergency...\n\nğŸŒ Creating Spanish phrasebook...\nğŸ“ Translating Greetings...\nğŸ“ Translating Basic Needs...\nğŸ“ Translating Transportation...\nğŸ“ Translating Food & Dining...\nğŸ“ Translating Emergency...\n\nğŸŒ Creating French phrasebook...\nğŸ“ Translating Greetings...\nğŸ“ Translating Basic Needs...\nğŸ“ Translating Transportation...\nğŸ“ Translating Food & Dining...\nğŸ“ Translating Emergency...\nğŸ§ª TRANSLATION ACCURACY TESTING\n==================================================\n\nğŸ“ Test Case 1:\nEnglish: Hello, how are you?\nâ±ï¸ Translation completed in 0.01 seconds (GPU: False)\nâ±ï¸ Translation completed in 0.01 seconds (GPU: False)\nArabic Result: âŒ No reliable translation found\nArabic Expected: Ù…Ø±Ø­Ø¨Ø§ØŒ ÙƒÙŠÙ Ø­Ø§Ù„ÙƒØŸ\nChinese Result: âŒ No reliable translation found\nChinese Expected: ä½ å¥½ï¼Œä½ å¥½å—ï¼Ÿ\n------------------------------\n\nğŸ“ Test Case 2:\nEnglish: Thank you very much\nâ±ï¸ Translation completed in 0.01 seconds (GPU: False)\nâ±ï¸ Translation completed in 0.01 seconds (GPU: False)\nArabic Result: âŒ No reliable translation found\nArabic Expected: Ø´ÙƒØ±Ø§ Ø¬Ø²ÙŠÙ„Ø§\nChinese Result: âŒ No reliable translation found\nChinese Expected: éå¸¸æ„Ÿè°¢\n------------------------------\n\nğŸ“ Test Case 3:\nEnglish: How much does this scooter cost for 1 day?\nâ±ï¸ Translation completed in 0.01 seconds (GPU: False)\nâ±ï¸ Translation completed in 0.01 seconds (GPU: False)\nArabic Result: ÙƒÙ… ØªÙƒÙ„ÙØ© Ù‡Ø°Ø§ Ø§Ù„Ø¯Ø±Ø§Ø¬Ø© Ø§Ù„Ù†Ø§Ø±ÙŠØ© Ù„Ù…Ø¯Ø© ÙŠÙˆÙ… ÙˆØ§Ø­Ø¯ØŸ\nArabic Expected: ÙƒÙ… ØªÙƒÙ„ÙØ© Ù‡Ø°Ø§ Ø§Ù„Ø¯Ø±Ø§Ø¬Ø© Ø§Ù„Ù†Ø§Ø±ÙŠØ© Ù„Ù…Ø¯Ø© ÙŠÙˆÙ… ÙˆØ§Ø­Ø¯ØŸ\nChinese Result: è¿™è¾†è¸æ¿è½¦ä¸€å¤©å¤šå°‘é’±ï¼Ÿ\nChinese Expected: è¿™è¾†è¸æ¿è½¦ä¸€å¤©å¤šå°‘é’±ï¼Ÿ\n------------------------------\nğŸ”§ TROUBLESHOOTING GUIDE\n========================================\nâŒ Issue: Model not found\nâœ… Solution: Ensure Gemma 3N dataset is added to notebook inputs\n\nâŒ Issue: Translation fails\nâœ… Solution: Verify TF_LITE_EMBEDDER and TOKENIZER_MODEL are extracted; check phrasebook\n\nâŒ Issue: Out of memory\nâœ… Solution: Restart kernel and limit input text length\n\nâŒ Issue: Language not supported\nâœ… Solution: Add translations to phrasebook for the target language\n\nâŒ Issue: GPU delegate not working\nâœ… Solution: Ensure TensorFlow is up-to-date; verify GPU availability with nvidia-smi\n\nâŒ Issue: EMBEDDING_LOOKUP op not supported\nâœ… Solution: Update TensorFlow to 2.16.0 or higher; ensure model compatibility\n\nğŸ” Verifying Environment\nTensorFlow version: 2.18.0\nTensorFlow GPU available: True\n\nğŸ” Verifying GPU Usage\nSat Jun 28 02:23:31 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n| N/A   35C    P0             31W /  250W |     257MiB /  16384MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1751077411.653676      35 gpu_device.cc:2022] Created device /device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"#!/usr/bin/env python3\n\"\"\"\nSimplified Gemma 3N Translation with TensorFlow Lite\n\"\"\"\n\nimport os\nimport numpy as np\nimport tensorflow as tf\nimport sentencepiece as spm\nimport zipfile\n\n# Paths\nMODEL_PATH = \"/kaggle/input/gemma-3n/tflite/gemma-3n-e2b-it-int4/1/gemma-3n-E2B-it-int4.task\"\nEXTRACT_DIR = \"/tmp/gemma3n_extracted\"\n\n# Verify model file\nif not os.path.exists(MODEL_PATH):\n    print(f\"âŒ Model file not found at {MODEL_PATH}\")\n    exit(1)\nprint(f\"âœ… Model found: {os.path.getsize(MODEL_PATH) / (1024*1024):.1f} MB\")\n\nclass SimpleTranslator:\n    def __init__(self, model_path: str):\n        \"\"\"Initialize translator with TFLite model and tokenizer\"\"\"\n        self.model_path = model_path\n        self.tokenizer = None\n        self.interpreter = None\n        self._setup()\n\n    def _setup(self):\n        \"\"\"Extract model and load tokenizer and interpreter\"\"\"\n        try:\n            # Extract model components\n            os.makedirs(EXTRACT_DIR, exist_ok=True)\n            with zipfile.ZipFile(self.model_path, 'r') as zf:\n                zf.extractall(EXTRACT_DIR)\n            print(f\"âœ… Model components extracted to {EXTRACT_DIR}\")\n\n            # Load tokenizer\n            tokenizer_path = os.path.join(EXTRACT_DIR, 'TOKENIZER_MODEL')\n            if not os.path.exists(tokenizer_path):\n                raise FileNotFoundError(f\"Tokenizer model not found at {tokenizer_path}\")\n            self.tokenizer = spm.SentencePieceProcessor()\n            self.tokenizer.Load(tokenizer_path)\n            print(f\"âœ… Tokenizer loaded: {self.tokenizer.GetPieceSize()} tokens\")\n\n            # Load TFLite model\n            embedder_path = os.path.join(EXTRACT_DIR, 'TF_LITE_EMBEDDER')\n            if not os.path.exists(embedder_path):\n                raise FileNotFoundError(f\"Embedder model not found at {embedder_path}\")\n            self.interpreter = tf.lite.Interpreter(model_path=embedder_path, num_threads=4)\n            self.interpreter.allocate_tensors()\n            print(\"âœ… Model loaded (CPU)\")\n\n            # Debug: Print input tensor details\n            input_details = self.interpreter.get_input_details()\n            print(f\"ğŸ” Input tensor details: {input_details}\")\n\n        except Exception as e:\n            print(f\"âŒ Setup error: {str(e)}\")\n            self.interpreter = None\n            self.tokenizer = None\n\n    def translate(self, text: str, target_language: str = \"Arabic\", source_language: str = \"English\") -> str:\n        \"\"\"Translate text using Gemma 3N model\"\"\"\n        if not self.interpreter or not self.tokenizer:\n            return \"âŒ Model not initialized\"\n\n        # Prepare input prompt for translation\n        prompt = f\"Translate from {source_language} to {target_language}: {text}\"\n        tokens = self.tokenizer.EncodeAsIds(prompt)[:128]  # Limit input length\n        if not tokens:\n            return \"âŒ Invalid input text\"\n\n        # Get input tensor details\n        input_details = self.interpreter.get_input_details()\n        output_details = self.interpreter.get_output_details()\n\n        # Reshape input to match expected dimensions (e.g., [1, seq_length] or [1, 1])\n        # Assume model expects [batch_size, sequence_length]\n        input_shape = input_details[0]['shape']\n        print(f\"ğŸ” Expected input shape: {input_shape}, Input tokens length: {len(tokens)}\")\n        \n        # Adjust input_data to match expected shape\n        if len(input_shape) == 2:  # Expecting [batch_size, sequence_length]\n            input_data = np.array([tokens], dtype=np.int32)  # Shape: [1, seq_length]\n        else:  # Expecting [batch_size, 1] or similar\n            input_data = np.array([[tokens[0]]], dtype=np.int32)  # Single token for iterative processing\n\n        try:\n            self.interpreter.set_tensor(input_details[0]['index'], input_data)\n            self.interpreter.invoke()\n            output_tokens = self.interpreter.get_tensor(output_details[0]['index'])\n            translation = self.tokenizer.Decode(output_tokens[0])\n            return translation.strip()\n        except Exception as e:\n            return f\"âŒ Translation error: {str(e)}\"\n\n# Initialize translator\ntranslator = SimpleTranslator(MODEL_PATH)\n\n# Example translations\ntest_phrases = [\n    \"Hello, how are you?\",\n    \"How much does this scooter cost for 1 day?\",\n    \"Where is the nearest restaurant?\"\n]\n\nprint(\"\\nğŸŒ Translation Examples\")\nprint(\"=\" * 40)\nfor phrase in test_phrases:\n    print(f\"\\nğŸ‡ºğŸ‡¸ English: {phrase}\")\n    arabic = translator.translate(phrase, \"Arabic\")\n    print(f\"ğŸ‡¸ğŸ‡¦ Arabic: {arabic}\")\n    chinese = translator.translate(phrase, \"Chinese\")\n    print(f\"ğŸ‡¨ğŸ‡³ Chinese: {chinese}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-28T02:23:33.490752Z","iopub.execute_input":"2025-06-28T02:23:33.491420Z","iopub.status.idle":"2025-06-28T02:23:43.167894Z","shell.execute_reply.started":"2025-06-28T02:23:33.491392Z","shell.execute_reply":"2025-06-28T02:23:43.167192Z"}},"outputs":[{"name":"stdout","text":"âœ… Model found: 2990.9 MB\nâœ… Model components extracted to /tmp/gemma3n_extracted\nâœ… Tokenizer loaded: 262144 tokens\nâœ… Model loaded (CPU)\nğŸ” Input tensor details: [{'name': 'embedder_token_ids:0', 'index': 0, 'shape': array([1, 1], dtype=int32), 'shape_signature': array([-1, -1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n\nğŸŒ Translation Examples\n========================================\n\nğŸ‡ºğŸ‡¸ English: Hello, how are you?\nğŸ” Expected input shape: [1 1], Input tokens length: 12\nğŸ‡¸ğŸ‡¦ Arabic: âŒ Translation error: Cannot set tensor: Dimension mismatch. Got 12 but expected 1 for dimension 1 of input 0.\nğŸ” Expected input shape: [1 1], Input tokens length: 12\nğŸ‡¨ğŸ‡³ Chinese: âŒ Translation error: Cannot set tensor: Dimension mismatch. Got 12 but expected 1 for dimension 1 of input 0.\n\nğŸ‡ºğŸ‡¸ English: How much does this scooter cost for 1 day?\nğŸ” Expected input shape: [1 1], Input tokens length: 17\nğŸ‡¸ğŸ‡¦ Arabic: âŒ Translation error: Cannot set tensor: Dimension mismatch. Got 17 but expected 1 for dimension 1 of input 0.\nğŸ” Expected input shape: [1 1], Input tokens length: 17\nğŸ‡¨ğŸ‡³ Chinese: âŒ Translation error: Cannot set tensor: Dimension mismatch. Got 17 but expected 1 for dimension 1 of input 0.\n\nğŸ‡ºğŸ‡¸ English: Where is the nearest restaurant?\nğŸ” Expected input shape: [1 1], Input tokens length: 12\nğŸ‡¸ğŸ‡¦ Arabic: âŒ Translation error: Cannot set tensor: Dimension mismatch. Got 12 but expected 1 for dimension 1 of input 0.\nğŸ” Expected input shape: [1 1], Input tokens length: 12\nğŸ‡¨ğŸ‡³ Chinese: âŒ Translation error: Cannot set tensor: Dimension mismatch. Got 12 but expected 1 for dimension 1 of input 0.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}